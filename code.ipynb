{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn\n",
    "import torch.nn.functional as FF\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Public\n",
    "dataset = 'Task_2_data_public'\n",
    "\n",
    "with open(f\"data/{dataset}/intervention_0.json\", mode=\"r\") as F:\n",
    "    data_0 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_1.json\", mode=\"r\") as F:\n",
    "    data_1 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_2.json\", mode=\"r\") as F:\n",
    "    data_2 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_3.json\", mode=\"r\") as F:\n",
    "    data_3 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_4.json\", mode=\"r\") as F:\n",
    "    data_4 = json.load(fp=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Local\n",
    "dataset = 'Task_2_data_local_dev'\n",
    "\n",
    "with open(f\"data/{dataset}/intervention_0.json\", mode=\"r\") as F:\n",
    "    local_0 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_1.json\", mode=\"r\") as F:\n",
    "    local_1 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_2.json\", mode=\"r\") as F:\n",
    "    local_2 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_3.json\", mode=\"r\") as F:\n",
    "    local_3 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_4.json\", mode=\"r\") as F:\n",
    "    local_4 = json.load(fp=F)\n",
    "\n",
    "label = np.load(\"data/Task_2_data_local_dev/cate_estimate.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Private\n",
    "\n",
    "dataset = 'Task_2_data_private'\n",
    "\n",
    "with open(f\"data/{dataset}/intervention_0.json\", mode=\"r\") as F:\n",
    "    private_0 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_1.json\", mode=\"r\") as F:\n",
    "    private_1 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_2.json\", mode=\"r\") as F:\n",
    "    private_2 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_3.json\", mode=\"r\") as F:\n",
    "    private_3 = json.load(fp=F)\n",
    "with open(f\"data/{dataset}/intervention_4.json\", mode=\"r\") as F:\n",
    "    private_4 = json.load(fp=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataset):\n",
    "    processed = []\n",
    "    for i in range(len(dataset)):\n",
    "        processed.append(\n",
    "            [\n",
    "                [[i[0]]+i[1:51]+[i[int(i[0])]] for i in dataset[i]['conditioning']],\n",
    "                dataset[i]['intervention'][0][0],\n",
    "                dataset[i]['reference'][0][0],\n",
    "                dataset[i]['effect_mask'][2].index(True),\n",
    "            ]\n",
    "        )\n",
    "    return processed\n",
    "\n",
    "processed_0 = process_data(data_0)\n",
    "processed_1 = process_data(data_1)\n",
    "processed_2 = process_data(data_2)\n",
    "processed_3 = process_data(data_3)\n",
    "processed_4 = process_data(data_4)\n",
    "\n",
    "local_0 = process_data(local_0)\n",
    "local_1 = process_data(local_1)\n",
    "local_2 = process_data(local_2)\n",
    "local_3 = process_data(local_3)\n",
    "local_4 = process_data(local_4)\n",
    "\n",
    "private_0 = process_data(private_0)\n",
    "private_1 = process_data(private_1)\n",
    "private_2 = process_data(private_2)\n",
    "private_3 = process_data(private_3)\n",
    "private_4 = process_data(private_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.GRU(batch_first=True, input_size=200+50+1, hidden_size=256)\n",
    "        self.embedding = nn.Embedding(50, 200)\n",
    "        self.fc = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 50)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # initialize\n",
    "        # for name, param in self.named_parameters():\n",
    "        #     if 'weight' in name:\n",
    "        #         nn.init.xavier_normal_(param)\n",
    "\n",
    "    def forward(self, input):\n",
    "        kc = input[:, :, 0].long()\n",
    "        state = input[:, :, 1:51]\n",
    "        ans = input[:, :, 50:51]\n",
    "        knows = self.embedding(kc)\n",
    "\n",
    "        input = torch.cat([\n",
    "            knows, state, ans\n",
    "        ], dim=-1)\n",
    "\n",
    "        out, h = self.model(input)\n",
    "        out = self.dropout(out)\n",
    "        return self.fc2(\n",
    "                FF.relu(\n",
    "                    self.fc(out)\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def predict(self, input, h=None):\n",
    "        if h is None:\n",
    "            kc = input[:, 0].long()\n",
    "            state = input[:, 1:51]\n",
    "            ans = input[:, 50:51]\n",
    "            knows = self.embedding(kc)\n",
    "            input = torch.cat([\n",
    "                knows, state, ans\n",
    "            ], dim=-1)\n",
    "            out, h = self.model(input)\n",
    "        else:\n",
    "            kc = input[:, 0].long()\n",
    "            state = input[:, 1:51]\n",
    "            ans = input[:, 50:51]\n",
    "            knows = self.embedding(kc)\n",
    "            input = torch.cat([\n",
    "                knows, state, ans\n",
    "            ], dim=-1)\n",
    "            out, h = self.model(input, h)\n",
    "\n",
    "        return self.fc2(\n",
    "                FF.relu(\n",
    "                    self.fc(out)\n",
    "                )\n",
    "            ), h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils for multi-lengths\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "def tensor2list(tensor: Tensor):\n",
    "    return tensor.cpu().tolist()\n",
    "\n",
    "def length2mask(length, max_len, valid_mask_val, invalid_mask_val):\n",
    "    mask = []\n",
    "\n",
    "    if isinstance(valid_mask_val, Tensor):\n",
    "        valid_mask_val = tensor2list(valid_mask_val)\n",
    "    if isinstance(invalid_mask_val, Tensor):\n",
    "        invalid_mask_val = tensor2list(invalid_mask_val)\n",
    "    if isinstance(length, Tensor):\n",
    "        length = tensor2list(length)\n",
    "\n",
    "    for _len in length:\n",
    "        mask.append([valid_mask_val] * _len + [invalid_mask_val] * (max_len - _len))\n",
    "\n",
    "    return torch.tensor(mask)\n",
    "\n",
    "\n",
    "def get_sequence_mask(shape, sequence_length, axis=1):\n",
    "    assert axis <= len(shape)\n",
    "    mask_shape = shape[axis + 1:]\n",
    "\n",
    "    valid_mask_val = torch.ones(mask_shape)\n",
    "    invalid_mask_val = torch.zeros(mask_shape)\n",
    "\n",
    "    max_len = shape[axis]\n",
    "\n",
    "    return length2mask(sequence_length, max_len, valid_mask_val, invalid_mask_val)\n",
    "\n",
    "\n",
    "def sequence_mask(tensor: Tensor, sequence_length, axis=1):\n",
    "    mask = get_sequence_mask(tensor.shape, sequence_length, axis).to(tensor.device)\n",
    "    return tensor * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding sequences\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_data(dataset):\n",
    "    return_set = [torch.Tensor(i[0]) for i in dataset]\n",
    "    origin_len = [len(i) for i in return_set]\n",
    "    return_set = pad_sequence(return_set, batch_first=True)\n",
    "    return return_set, origin_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:0 Epoch: 0 Eval_loss: 0.06101906672120094\n",
      "Train:0 Epoch: 1 Eval_loss: 0.025600681081414223\n",
      "Train:0 Epoch: 2 Eval_loss: 0.02471286989748478\n",
      "Train:0 Epoch: 3 Eval_loss: 0.015368201769888401\n",
      "Train:0 Epoch: 4 Eval_loss: 0.013758021406829357\n",
      "Train:0 Epoch: 5 Eval_loss: 0.012315604835748672\n",
      "Train:0 Epoch: 6 Eval_loss: 0.010592114180326462\n",
      "Train:0 Epoch: 7 Eval_loss: 0.009987959638237953\n",
      "Train:0 Epoch: 8 Eval_loss: 0.008855033665895462\n",
      "Train:0 Epoch: 9 Eval_loss: 0.008183583617210388\n",
      "Train:0 Epoch: 10 Eval_loss: 0.008373884484171867\n",
      "Train:0 Epoch: 11 Eval_loss: 0.007388702593743801\n",
      "Train:0 Epoch: 12 Eval_loss: 0.0067795137874782085\n",
      "Train:0 Epoch: 13 Eval_loss: 0.0064430758357048035\n",
      "Train:0 Epoch: 14 Eval_loss: 0.005730226170271635\n",
      "Train:0 Epoch: 15 Eval_loss: 0.005419522523880005\n",
      "Train:0 Epoch: 16 Eval_loss: 0.005258436314761639\n",
      "Train:0 Epoch: 17 Eval_loss: 0.0050285495817661285\n",
      "Train:0 Epoch: 18 Eval_loss: 0.004776335321366787\n",
      "Train:0 Epoch: 19 Eval_loss: 0.0046470267698168755\n",
      "Train:0 Epoch: 20 Eval_loss: 0.0045335302129387856\n",
      "Train:0 Epoch: 21 Eval_loss: 0.004360329359769821\n",
      "Train:0 Epoch: 22 Eval_loss: 0.00433198269456625\n",
      "Train:0 Epoch: 23 Eval_loss: 0.004199544433504343\n",
      "Train:0 Epoch: 24 Eval_loss: 0.0041627646423876286\n",
      "Train:0 Epoch: 25 Eval_loss: 0.004106385167688131\n",
      "Train:0 Epoch: 26 Eval_loss: 0.004075623117387295\n",
      "Train:0 Epoch: 27 Eval_loss: 0.0039901938289403915\n",
      "Train:0 Epoch: 28 Eval_loss: 0.003856332739815116\n",
      "Train:0 Epoch: 29 Eval_loss: 0.0037811361253261566\n",
      "Train:0 Epoch: 30 Eval_loss: 0.0036821127869188786\n",
      "Train:0 Epoch: 31 Eval_loss: 0.0036487525794655085\n",
      "Train:0 Epoch: 32 Eval_loss: 0.0036860452964901924\n",
      "Train:0 Epoch: 33 Eval_loss: 0.003552537178620696\n",
      "Train:0 Epoch: 34 Eval_loss: 0.0035344597417861223\n",
      "Train:0 Epoch: 35 Eval_loss: 0.003401275025680661\n",
      "Train:0 Epoch: 36 Eval_loss: 0.003372869221493602\n",
      "Train:0 Epoch: 37 Eval_loss: 0.003324792254716158\n",
      "Train:0 Epoch: 38 Eval_loss: 0.003253143047913909\n",
      "Train:0 Epoch: 39 Eval_loss: 0.0032284206245094538\n",
      "Train:0 Epoch: 40 Eval_loss: 0.003237834433093667\n",
      "Train:0 Epoch: 41 Eval_loss: 0.0033678996842354536\n",
      "Train:0 Epoch: 42 Eval_loss: 0.0033035746309906244\n",
      "Train:0 Epoch: 43 Eval_loss: 0.0032813327852636576\n",
      "Train:0 Epoch: 44 Eval_loss: 0.0031164272222667933\n",
      "Train:0 Epoch: 45 Eval_loss: 0.003137820167466998\n",
      "Train:0 Epoch: 46 Eval_loss: 0.003248984459787607\n",
      "Train:0 Epoch: 47 Eval_loss: 0.003068360732868314\n",
      "Train:0 Epoch: 48 Eval_loss: 0.002940376056358218\n",
      "Train:0 Epoch: 49 Eval_loss: 0.002930819056928158\n",
      "Train:0 Epoch: 50 Eval_loss: 0.0028678718954324722\n",
      "Train:0 Epoch: 51 Eval_loss: 0.0028551446739584208\n",
      "Train:0 Epoch: 52 Eval_loss: 0.0028234864585101604\n",
      "Train:0 Epoch: 53 Eval_loss: 0.0028243588749319315\n",
      "Train:0 Epoch: 54 Eval_loss: 0.002764528850093484\n",
      "Train:0 Epoch: 55 Eval_loss: 0.002684748964384198\n",
      "Train:0 Epoch: 56 Eval_loss: 0.0026902833487838507\n",
      "Train:0 Epoch: 57 Eval_loss: 0.0026877617929130793\n",
      "Train:0 Epoch: 58 Eval_loss: 0.002715995302423835\n",
      "Train:0 Epoch: 59 Eval_loss: 0.002798074157908559\n",
      "Train:0 Epoch: 60 Eval_loss: 0.002716739196330309\n",
      "Train:0 Epoch: 61 Eval_loss: 0.0026222476735711098\n",
      "Train:0 Epoch: 62 Eval_loss: 0.0025217109359800816\n",
      "Train:0 Epoch: 63 Eval_loss: 0.0025212569162249565\n",
      "Train:0 Epoch: 64 Eval_loss: 0.0025412074755877256\n",
      "Train:0 Epoch: 65 Eval_loss: 0.00249147554859519\n",
      "Train:0 Epoch: 66 Eval_loss: 0.0024620573967695236\n",
      "Train:0 Epoch: 67 Eval_loss: 0.002489578677341342\n",
      "Train:0 Epoch: 68 Eval_loss: 0.0023493035696446896\n",
      "Train:0 Epoch: 69 Eval_loss: 0.002303858520463109\n",
      "Train:0 Epoch: 70 Eval_loss: 0.002285626484081149\n",
      "Train:0 Epoch: 71 Eval_loss: 0.002258828142657876\n",
      "Train:0 Epoch: 72 Eval_loss: 0.0022451586555689573\n",
      "Train:0 Epoch: 73 Eval_loss: 0.00219941814430058\n",
      "Train:0 Epoch: 74 Eval_loss: 0.002231952268630266\n",
      "Train:0 Epoch: 75 Eval_loss: 0.0022034808062016964\n",
      "Train:0 Epoch: 76 Eval_loss: 0.0021127229556441307\n",
      "Train:0 Epoch: 77 Eval_loss: 0.002080735517665744\n",
      "Train:0 Epoch: 78 Eval_loss: 0.0021191458217799664\n",
      "Train:0 Epoch: 79 Eval_loss: 0.002039736369624734\n",
      "Train:0 Epoch: 80 Eval_loss: 0.002045885194092989\n",
      "Train:0 Epoch: 81 Eval_loss: 0.002073292387649417\n",
      "Train:0 Epoch: 82 Eval_loss: 0.00201586214825511\n",
      "Train:0 Epoch: 83 Eval_loss: 0.0019979504868388176\n",
      "Train:0 Epoch: 84 Eval_loss: 0.002042839303612709\n",
      "Train:0 Epoch: 85 Eval_loss: 0.0019207033328711987\n",
      "Train:0 Epoch: 86 Eval_loss: 0.001925055985338986\n",
      "Train:0 Epoch: 87 Eval_loss: 0.0018748784204944968\n",
      "Train:0 Epoch: 88 Eval_loss: 0.00189490697812289\n",
      "Train:0 Epoch: 89 Eval_loss: 0.001838057767599821\n",
      "Train:0 Epoch: 90 Eval_loss: 0.001901561627164483\n",
      "Train:0 Epoch: 91 Eval_loss: 0.001876387046650052\n",
      "Train:0 Epoch: 92 Eval_loss: 0.0018573065754026175\n",
      "Train:0 Epoch: 93 Eval_loss: 0.001912109088152647\n",
      "Train:0 Epoch: 94 Eval_loss: 0.0018515033880248666\n",
      "Train:0 Epoch: 95 Eval_loss: 0.0018246520776301622\n",
      "Train:0 Epoch: 96 Eval_loss: 0.0018036102410405874\n",
      "Train:0 Epoch: 97 Eval_loss: 0.0017916853539645672\n",
      "Train:0 Epoch: 98 Eval_loss: 0.0017396437469869852\n",
      "Train:0 Epoch: 99 Eval_loss: 0.0017181881703436375\n",
      "Train:0 Epoch: 100 Eval_loss: 0.001736388891004026\n",
      "Train:0 Epoch: 101 Eval_loss: 0.0016985931433737278\n",
      "Train:0 Epoch: 102 Eval_loss: 0.001699858927167952\n",
      "Train:0 Epoch: 103 Eval_loss: 0.00164588144980371\n",
      "Train:0 Epoch: 104 Eval_loss: 0.0015973033150658011\n",
      "Train:0 Epoch: 105 Eval_loss: 0.0015863492153584957\n",
      "Train:0 Epoch: 106 Eval_loss: 0.0015928150387480855\n",
      "Train:0 Epoch: 107 Eval_loss: 0.0016236428637057543\n",
      "Train:0 Epoch: 108 Eval_loss: 0.0016041419003158808\n",
      "Train:0 Epoch: 109 Eval_loss: 0.001551623223349452\n",
      "Train:0 Epoch: 110 Eval_loss: 0.0015218791086226702\n",
      "Train:0 Epoch: 111 Eval_loss: 0.0015507412608712912\n",
      "Train:0 Epoch: 112 Eval_loss: 0.001544193597510457\n",
      "Train:0 Epoch: 113 Eval_loss: 0.0015504418406635523\n",
      "Train:0 Epoch: 114 Eval_loss: 0.0015285883564502\n",
      "Train:0 Epoch: 115 Eval_loss: 0.0015291072195395827\n",
      "Train:0 Epoch: 116 Eval_loss: 0.001528102089650929\n",
      "Train:0 Epoch: 117 Eval_loss: 0.0015001355204731226\n",
      "Train:0 Epoch: 118 Eval_loss: 0.0014724809443578124\n",
      "Train:0 Epoch: 119 Eval_loss: 0.0014617880806326866\n",
      "Train:0 Epoch: 120 Eval_loss: 0.0014817457413300872\n",
      "Train:0 Epoch: 121 Eval_loss: 0.001496733631938696\n",
      "Train:0 Epoch: 122 Eval_loss: 0.0014256115537136793\n",
      "Train:0 Epoch: 123 Eval_loss: 0.0014203119790181518\n",
      "Train:0 Epoch: 124 Eval_loss: 0.001351261860691011\n",
      "Train:0 Epoch: 125 Eval_loss: 0.0013434261782094836\n",
      "Train:0 Epoch: 126 Eval_loss: 0.0014100248226895928\n",
      "Train:0 Epoch: 127 Eval_loss: 0.0013466603122651577\n",
      "Train:0 Epoch: 128 Eval_loss: 0.0013751329388469458\n",
      "Train:0 Epoch: 129 Eval_loss: 0.0013481506612151861\n",
      "Train:0 Epoch: 130 Eval_loss: 0.0013046335661783814\n",
      "Train:0 Epoch: 131 Eval_loss: 0.0012686393456533551\n",
      "Train:0 Epoch: 132 Eval_loss: 0.0013304217718541622\n",
      "Train:0 Epoch: 133 Eval_loss: 0.001295515801757574\n",
      "Train:0 Epoch: 134 Eval_loss: 0.0012719060759991407\n",
      "Train:0 Epoch: 135 Eval_loss: 0.0012518498115241528\n",
      "Train:0 Epoch: 136 Eval_loss: 0.0012956795981153846\n",
      "Train:0 Epoch: 137 Eval_loss: 0.0013229207834228873\n",
      "Train:0 Epoch: 138 Eval_loss: 0.0013046447420492768\n",
      "Train:0 Epoch: 139 Eval_loss: 0.0012780731776729226\n",
      "Train:0 Epoch: 140 Eval_loss: 0.0012177309254184365\n",
      "Train:0 Epoch: 141 Eval_loss: 0.0011787082767114043\n",
      "Train:0 Epoch: 142 Eval_loss: 0.0012118773302063346\n",
      "Train:0 Epoch: 143 Eval_loss: 0.0011805923422798514\n",
      "Train:0 Epoch: 144 Eval_loss: 0.0012146756052970886\n",
      "Train:0 Epoch: 145 Eval_loss: 0.0011578708654269576\n",
      "Train:0 Epoch: 146 Eval_loss: 0.0011371747823432088\n",
      "Train:0 Epoch: 147 Eval_loss: 0.0012083242181688547\n",
      "Train:0 Epoch: 148 Eval_loss: 0.0011398571077734232\n",
      "Train:0 Epoch: 149 Eval_loss: 0.001099211280234158\n",
      "Train:0 Epoch: 150 Eval_loss: 0.0011111486237496138\n",
      "Train:0 Epoch: 151 Eval_loss: 0.001098571578040719\n",
      "Train:0 Epoch: 152 Eval_loss: 0.0011126172030344605\n",
      "Train:0 Epoch: 153 Eval_loss: 0.0010985940461978316\n",
      "Train:0 Epoch: 154 Eval_loss: 0.0010799502488225698\n",
      "Train:0 Epoch: 155 Eval_loss: 0.0010683860164135695\n",
      "Train:0 Epoch: 156 Eval_loss: 0.0011354442685842514\n",
      "Train:0 Epoch: 157 Eval_loss: 0.0011739376932382584\n",
      "Train:0 Epoch: 158 Eval_loss: 0.0011408133432269096\n",
      "Train:0 Epoch: 159 Eval_loss: 0.0012251551961526275\n",
      "Train:0 Epoch: 160 Eval_loss: 0.0010625467402860522\n",
      "Train:0 Epoch: 161 Eval_loss: 0.0010284674353897572\n",
      "Train:0 Epoch: 162 Eval_loss: 0.0009917855495586991\n",
      "Train:0 Epoch: 163 Eval_loss: 0.001059908070601523\n",
      "Train:0 Epoch: 164 Eval_loss: 0.000991308712400496\n",
      "Train:0 Epoch: 165 Eval_loss: 0.0010722829028964043\n",
      "Train:0 Epoch: 166 Eval_loss: 0.0009907224448397756\n",
      "Train:0 Epoch: 167 Eval_loss: 0.0009695058106444776\n",
      "Train:0 Epoch: 168 Eval_loss: 0.0009700692025944591\n",
      "Train:0 Epoch: 169 Eval_loss: 0.0009953361004590988\n",
      "Train:0 Epoch: 170 Eval_loss: 0.0009835733799263835\n",
      "Train:0 Epoch: 171 Eval_loss: 0.0009476291597820818\n",
      "Train:0 Epoch: 172 Eval_loss: 0.0009301609825342894\n",
      "Train:0 Epoch: 173 Eval_loss: 0.0008976228418760002\n",
      "Train:0 Epoch: 174 Eval_loss: 0.000863787077832967\n",
      "Train:0 Epoch: 175 Eval_loss: 0.0008637572755105793\n",
      "Train:0 Epoch: 176 Eval_loss: 0.0008751899003982544\n",
      "Train:0 Epoch: 177 Eval_loss: 0.0008824702817946672\n",
      "Train:0 Epoch: 178 Eval_loss: 0.0008418011129833758\n",
      "Train:0 Epoch: 179 Eval_loss: 0.0008579048444516957\n",
      "Train:0 Epoch: 180 Eval_loss: 0.0008684117929078639\n",
      "Train:0 Epoch: 181 Eval_loss: 0.0008380700019188225\n",
      "Train:0 Epoch: 182 Eval_loss: 0.0008999424753710628\n",
      "Train:0 Epoch: 183 Eval_loss: 0.0009194454760290682\n",
      "Train:0 Epoch: 184 Eval_loss: 0.0008869572775438428\n",
      "Train:0 Epoch: 185 Eval_loss: 0.0009196607279591262\n",
      "Train:0 Epoch: 186 Eval_loss: 0.0008416959317401052\n",
      "Train:0 Epoch: 187 Eval_loss: 0.0008594007813371718\n",
      "Train:0 Epoch: 188 Eval_loss: 0.0007882799254730344\n",
      "Train:0 Epoch: 189 Eval_loss: 0.0007867326494306326\n",
      "Train:0 Epoch: 190 Eval_loss: 0.0007520224899053574\n",
      "Train:0 Epoch: 191 Eval_loss: 0.000776110275182873\n",
      "Train:0 Epoch: 192 Eval_loss: 0.0007498342893086374\n",
      "Train:0 Epoch: 193 Eval_loss: 0.0007641632109880447\n",
      "Train:0 Epoch: 194 Eval_loss: 0.0007322089513763785\n",
      "Train:0 Epoch: 195 Eval_loss: 0.0007224227301776409\n",
      "Train:0 Epoch: 196 Eval_loss: 0.0007223925204016268\n",
      "Train:0 Epoch: 197 Eval_loss: 0.0007272257353179157\n",
      "Train:0 Epoch: 198 Eval_loss: 0.000706432037986815\n",
      "Train:0 Epoch: 199 Eval_loss: 0.0007245314191095531\n",
      "Train:0 Epoch: 200 Eval_loss: 0.0006990928668528795\n",
      "Train:0 Epoch: 201 Eval_loss: 0.0007180375978350639\n",
      "Train:0 Epoch: 202 Eval_loss: 0.0007478019106201828\n",
      "Train:0 Epoch: 203 Eval_loss: 0.0007424969226121902\n",
      "Train:0 Epoch: 204 Eval_loss: 0.0007736653788015246\n",
      "Train:0 Epoch: 205 Eval_loss: 0.0008200588636100292\n",
      "Train:0 Epoch: 206 Eval_loss: 0.0007133021135814488\n",
      "Train:0 Epoch: 207 Eval_loss: 0.0006846040487289429\n",
      "Train:0 Epoch: 208 Eval_loss: 0.0006783449207432568\n",
      "Train:0 Epoch: 209 Eval_loss: 0.0006739707896485925\n",
      "Train:0 Epoch: 210 Eval_loss: 0.0006531323888339102\n",
      "Train:0 Epoch: 211 Eval_loss: 0.0006444289465434849\n",
      "Train:0 Epoch: 212 Eval_loss: 0.0006144955405034125\n",
      "Train:0 Epoch: 213 Eval_loss: 0.0006096349097788334\n",
      "Train:0 Epoch: 214 Eval_loss: 0.0006290681776590645\n",
      "Train:0 Epoch: 215 Eval_loss: 0.0006229119026102126\n",
      "Train:0 Epoch: 216 Eval_loss: 0.0006299791857600212\n",
      "Train:0 Epoch: 217 Eval_loss: 0.0006056157290004194\n",
      "Train:0 Epoch: 218 Eval_loss: 0.0006087145302444696\n",
      "Train:0 Epoch: 219 Eval_loss: 0.0005727714742533863\n",
      "Train:0 Epoch: 220 Eval_loss: 0.000619593367446214\n",
      "Train:0 Epoch: 221 Eval_loss: 0.0006430817302316427\n",
      "Train:0 Epoch: 222 Eval_loss: 0.0006637890473939478\n",
      "Train:0 Epoch: 223 Eval_loss: 0.000639171339571476\n",
      "Train:0 Epoch: 224 Eval_loss: 0.0006255574407987297\n",
      "Train:0 Epoch: 225 Eval_loss: 0.0006347239250317216\n",
      "Train:0 Epoch: 226 Eval_loss: 0.0006345142028294504\n",
      "Train:0 Epoch: 227 Eval_loss: 0.0006189841660670936\n",
      "Train:0 Epoch: 228 Eval_loss: 0.0006415400421246886\n",
      "Train:1 Epoch: 0 Eval_loss: 0.06912614405155182\n",
      "Train:1 Epoch: 1 Eval_loss: 0.02734622173011303\n",
      "Train:1 Epoch: 2 Eval_loss: 0.021761447191238403\n",
      "Train:1 Epoch: 3 Eval_loss: 0.014934897422790527\n",
      "Train:1 Epoch: 4 Eval_loss: 0.012738666497170925\n",
      "Train:1 Epoch: 5 Eval_loss: 0.012144866399466991\n",
      "Train:1 Epoch: 6 Eval_loss: 0.01143298577517271\n",
      "Train:1 Epoch: 7 Eval_loss: 0.010573395527899265\n",
      "Train:1 Epoch: 8 Eval_loss: 0.00992025900632143\n",
      "Train:1 Epoch: 9 Eval_loss: 0.009348911233246326\n",
      "Train:1 Epoch: 10 Eval_loss: 0.009177163243293762\n",
      "Train:1 Epoch: 11 Eval_loss: 0.008653860539197922\n",
      "Train:1 Epoch: 12 Eval_loss: 0.008116208016872406\n",
      "Train:1 Epoch: 13 Eval_loss: 0.00754478108137846\n",
      "Train:1 Epoch: 14 Eval_loss: 0.007160223554819822\n",
      "Train:1 Epoch: 15 Eval_loss: 0.006689032539725304\n",
      "Train:1 Epoch: 16 Eval_loss: 0.0063076503574848175\n",
      "Train:1 Epoch: 17 Eval_loss: 0.005971502047032118\n",
      "Train:1 Epoch: 18 Eval_loss: 0.005832822062075138\n",
      "Train:1 Epoch: 19 Eval_loss: 0.005588477943092585\n",
      "Train:1 Epoch: 20 Eval_loss: 0.005359574221074581\n",
      "Train:1 Epoch: 21 Eval_loss: 0.005238417070358992\n",
      "Train:1 Epoch: 22 Eval_loss: 0.0050692372024059296\n",
      "Train:1 Epoch: 23 Eval_loss: 0.004896425176411867\n",
      "Train:1 Epoch: 24 Eval_loss: 0.004733911715447903\n",
      "Train:1 Epoch: 25 Eval_loss: 0.00470546493306756\n",
      "Train:1 Epoch: 26 Eval_loss: 0.004684180021286011\n",
      "Train:1 Epoch: 27 Eval_loss: 0.0044998726807534695\n",
      "Train:1 Epoch: 28 Eval_loss: 0.004385697189718485\n",
      "Train:1 Epoch: 29 Eval_loss: 0.004300561733543873\n",
      "Train:1 Epoch: 30 Eval_loss: 0.004294440150260925\n",
      "Train:1 Epoch: 31 Eval_loss: 0.00416550412774086\n",
      "Train:1 Epoch: 32 Eval_loss: 0.004098894540220499\n",
      "Train:1 Epoch: 33 Eval_loss: 0.0040412829257547855\n",
      "Train:1 Epoch: 34 Eval_loss: 0.004060074687004089\n",
      "Train:1 Epoch: 35 Eval_loss: 0.003989946097135544\n",
      "Train:1 Epoch: 36 Eval_loss: 0.003986745607107878\n",
      "Train:1 Epoch: 37 Eval_loss: 0.003983679227530956\n",
      "Train:1 Epoch: 38 Eval_loss: 0.0038805343210697174\n",
      "Train:1 Epoch: 39 Eval_loss: 0.0038299025036394596\n",
      "Train:1 Epoch: 40 Eval_loss: 0.0038223667070269585\n",
      "Train:1 Epoch: 41 Eval_loss: 0.003752494929358363\n",
      "Train:1 Epoch: 42 Eval_loss: 0.0037342903669923544\n",
      "Train:1 Epoch: 43 Eval_loss: 0.003685977542772889\n",
      "Train:1 Epoch: 44 Eval_loss: 0.0035836331080645323\n",
      "Train:1 Epoch: 45 Eval_loss: 0.0035466027911752462\n",
      "Train:1 Epoch: 46 Eval_loss: 0.0035475941840559244\n",
      "Train:1 Epoch: 47 Eval_loss: 0.003440605942159891\n",
      "Train:1 Epoch: 48 Eval_loss: 0.0034263432025909424\n",
      "Train:1 Epoch: 49 Eval_loss: 0.0033082959707826376\n",
      "Train:1 Epoch: 50 Eval_loss: 0.003348167520016432\n",
      "Train:1 Epoch: 51 Eval_loss: 0.003420006949454546\n",
      "Train:1 Epoch: 52 Eval_loss: 0.003354606218636036\n",
      "Train:1 Epoch: 53 Eval_loss: 0.00332643766887486\n",
      "Train:1 Epoch: 54 Eval_loss: 0.0032682660967111588\n",
      "Train:1 Epoch: 55 Eval_loss: 0.003472468350082636\n",
      "Train:1 Epoch: 56 Eval_loss: 0.003238504519686103\n",
      "Train:1 Epoch: 57 Eval_loss: 0.0034020531456917524\n",
      "Train:1 Epoch: 58 Eval_loss: 0.0033523384481668472\n",
      "Train:1 Epoch: 59 Eval_loss: 0.003354274434968829\n",
      "Train:1 Epoch: 60 Eval_loss: 0.0032618017867207527\n",
      "Train:1 Epoch: 61 Eval_loss: 0.0031931912526488304\n",
      "Train:1 Epoch: 62 Eval_loss: 0.00315558398142457\n",
      "Train:1 Epoch: 63 Eval_loss: 0.0030431027989834547\n",
      "Train:1 Epoch: 64 Eval_loss: 0.003037602175027132\n",
      "Train:1 Epoch: 65 Eval_loss: 0.0030304056126624346\n",
      "Train:1 Epoch: 66 Eval_loss: 0.0029519833624362946\n",
      "Train:1 Epoch: 67 Eval_loss: 0.0029860667418688536\n",
      "Train:1 Epoch: 68 Eval_loss: 0.0030631537083536386\n",
      "Train:1 Epoch: 69 Eval_loss: 0.003082203445956111\n",
      "Train:1 Epoch: 70 Eval_loss: 0.002938247984275222\n",
      "Train:1 Epoch: 71 Eval_loss: 0.002824886702001095\n",
      "Train:1 Epoch: 72 Eval_loss: 0.002779280999675393\n",
      "Train:1 Epoch: 73 Eval_loss: 0.0028744004666805267\n",
      "Train:1 Epoch: 74 Eval_loss: 0.0028453620616346598\n",
      "Train:1 Epoch: 75 Eval_loss: 0.0028549651615321636\n",
      "Train:1 Epoch: 76 Eval_loss: 0.0028393494430929422\n",
      "Train:1 Epoch: 77 Eval_loss: 0.0028501302003860474\n",
      "Train:1 Epoch: 78 Eval_loss: 0.0026785689406096935\n",
      "Train:1 Epoch: 79 Eval_loss: 0.0026309031527489424\n",
      "Train:1 Epoch: 80 Eval_loss: 0.0026280430611222982\n",
      "Train:1 Epoch: 81 Eval_loss: 0.0026215356774628162\n",
      "Train:1 Epoch: 82 Eval_loss: 0.002635578392073512\n",
      "Train:1 Epoch: 83 Eval_loss: 0.0026836972683668137\n",
      "Train:1 Epoch: 84 Eval_loss: 0.002640120219439268\n",
      "Train:1 Epoch: 85 Eval_loss: 0.0025867316871881485\n",
      "Train:1 Epoch: 86 Eval_loss: 0.0025928490795195103\n",
      "Train:1 Epoch: 87 Eval_loss: 0.0025487178936600685\n",
      "Train:1 Epoch: 88 Eval_loss: 0.00256622233428061\n",
      "Train:1 Epoch: 89 Eval_loss: 0.0025593966711312532\n",
      "Train:1 Epoch: 90 Eval_loss: 0.0024380984250456095\n",
      "Train:1 Epoch: 91 Eval_loss: 0.002361888065934181\n",
      "Train:1 Epoch: 92 Eval_loss: 0.002385386498644948\n",
      "Train:1 Epoch: 93 Eval_loss: 0.0023500663228332996\n",
      "Train:1 Epoch: 94 Eval_loss: 0.0023460877127945423\n",
      "Train:1 Epoch: 95 Eval_loss: 0.0023701980244368315\n",
      "Train:1 Epoch: 96 Eval_loss: 0.002245773561298847\n",
      "Train:1 Epoch: 97 Eval_loss: 0.0023631874937564135\n",
      "Train:1 Epoch: 98 Eval_loss: 0.0022702752612531185\n",
      "Train:1 Epoch: 99 Eval_loss: 0.0022256129886955023\n",
      "Train:1 Epoch: 100 Eval_loss: 0.0021244294475764036\n",
      "Train:1 Epoch: 101 Eval_loss: 0.002347692148759961\n",
      "Train:1 Epoch: 102 Eval_loss: 0.002254102611914277\n",
      "Train:1 Epoch: 103 Eval_loss: 0.0022070652339607477\n",
      "Train:1 Epoch: 104 Eval_loss: 0.002146695042029023\n",
      "Train:1 Epoch: 105 Eval_loss: 0.0021891931537538767\n",
      "Train:1 Epoch: 106 Eval_loss: 0.002137622330337763\n",
      "Train:1 Epoch: 107 Eval_loss: 0.002053376054391265\n",
      "Train:1 Epoch: 108 Eval_loss: 0.0020582189317792654\n",
      "Train:1 Epoch: 109 Eval_loss: 0.0019838502630591393\n",
      "Train:1 Epoch: 110 Eval_loss: 0.0020631677471101284\n",
      "Train:1 Epoch: 111 Eval_loss: 0.002013094024732709\n",
      "Train:1 Epoch: 112 Eval_loss: 0.0019981595687568188\n",
      "Train:1 Epoch: 113 Eval_loss: 0.0019960817880928516\n",
      "Train:1 Epoch: 114 Eval_loss: 0.0019970496650785208\n",
      "Train:1 Epoch: 115 Eval_loss: 0.0018979503074660897\n",
      "Train:1 Epoch: 116 Eval_loss: 0.0019384954357519746\n",
      "Train:1 Epoch: 117 Eval_loss: 0.0019527957774698734\n",
      "Train:1 Epoch: 118 Eval_loss: 0.001921854680404067\n",
      "Train:1 Epoch: 119 Eval_loss: 0.0018952033715322614\n",
      "Train:1 Epoch: 120 Eval_loss: 0.0018383451970294118\n",
      "Train:1 Epoch: 121 Eval_loss: 0.0017612904775887728\n",
      "Train:1 Epoch: 122 Eval_loss: 0.0017194750253111124\n",
      "Train:1 Epoch: 123 Eval_loss: 0.0017258875304833055\n",
      "Train:1 Epoch: 124 Eval_loss: 0.00174430210608989\n",
      "Train:1 Epoch: 125 Eval_loss: 0.0017308607930317521\n",
      "Train:1 Epoch: 126 Eval_loss: 0.0017370741115882993\n",
      "Train:1 Epoch: 127 Eval_loss: 0.0016979339998215437\n",
      "Train:1 Epoch: 128 Eval_loss: 0.0017067730659618974\n",
      "Train:1 Epoch: 129 Eval_loss: 0.0017091934569180012\n",
      "Train:1 Epoch: 130 Eval_loss: 0.0017144570592790842\n",
      "Train:1 Epoch: 131 Eval_loss: 0.0016793431714177132\n",
      "Train:1 Epoch: 132 Eval_loss: 0.0016594118205830455\n",
      "Train:1 Epoch: 133 Eval_loss: 0.0016312198713421822\n",
      "Train:1 Epoch: 134 Eval_loss: 0.001624356140382588\n",
      "Train:1 Epoch: 135 Eval_loss: 0.0015578089514747262\n",
      "Train:1 Epoch: 136 Eval_loss: 0.0015760817332193255\n",
      "Train:1 Epoch: 137 Eval_loss: 0.0014835490146651864\n",
      "Train:1 Epoch: 138 Eval_loss: 0.001492293318733573\n",
      "Train:1 Epoch: 139 Eval_loss: 0.0015114180278033018\n",
      "Train:1 Epoch: 140 Eval_loss: 0.0017078950768336654\n",
      "Train:1 Epoch: 141 Eval_loss: 0.001609048806130886\n",
      "Train:1 Epoch: 142 Eval_loss: 0.0015623457729816437\n",
      "Train:1 Epoch: 143 Eval_loss: 0.0015624864026904106\n",
      "Train:1 Epoch: 144 Eval_loss: 0.0014720327453687787\n",
      "Train:1 Epoch: 145 Eval_loss: 0.0014292768901214004\n",
      "Train:1 Epoch: 146 Eval_loss: 0.001434080651961267\n",
      "Train:1 Epoch: 147 Eval_loss: 0.001404137583449483\n",
      "Train:1 Epoch: 148 Eval_loss: 0.0013891214039176702\n",
      "Train:1 Epoch: 149 Eval_loss: 0.0013867185916751623\n",
      "Train:1 Epoch: 150 Eval_loss: 0.0013843229971826077\n",
      "Train:1 Epoch: 151 Eval_loss: 0.0013535289326682687\n",
      "Train:1 Epoch: 152 Eval_loss: 0.0013004811480641365\n",
      "Train:1 Epoch: 153 Eval_loss: 0.001296422560699284\n",
      "Train:1 Epoch: 154 Eval_loss: 0.001276507624424994\n",
      "Train:1 Epoch: 155 Eval_loss: 0.0012940374435856938\n",
      "Train:1 Epoch: 156 Eval_loss: 0.0012152136769145727\n",
      "Train:1 Epoch: 157 Eval_loss: 0.001172967255115509\n",
      "Train:1 Epoch: 158 Eval_loss: 0.0011939178220927715\n",
      "Train:1 Epoch: 159 Eval_loss: 0.0011675864225253463\n",
      "Train:1 Epoch: 160 Eval_loss: 0.0011649620719254017\n",
      "Train:1 Epoch: 161 Eval_loss: 0.0011341572972014546\n",
      "Train:1 Epoch: 162 Eval_loss: 0.001137648825533688\n",
      "Train:1 Epoch: 163 Eval_loss: 0.0011421388480812311\n",
      "Train:1 Epoch: 164 Eval_loss: 0.001145924674347043\n",
      "Train:1 Epoch: 165 Eval_loss: 0.001161074498668313\n",
      "Train:1 Epoch: 166 Eval_loss: 0.0011513890931382775\n",
      "Train:1 Epoch: 167 Eval_loss: 0.0011287144152447581\n",
      "Train:1 Epoch: 168 Eval_loss: 0.0011504747672006488\n",
      "Train:1 Epoch: 169 Eval_loss: 0.0011324884835630655\n",
      "Train:1 Epoch: 170 Eval_loss: 0.0010929780546575785\n",
      "Train:1 Epoch: 171 Eval_loss: 0.0010858557652682066\n",
      "Train:1 Epoch: 172 Eval_loss: 0.0010715568205341697\n",
      "Train:1 Epoch: 173 Eval_loss: 0.0010637472150847316\n",
      "Train:1 Epoch: 174 Eval_loss: 0.001074899104423821\n",
      "Train:1 Epoch: 175 Eval_loss: 0.0010917364852502942\n",
      "Train:1 Epoch: 176 Eval_loss: 0.001165695022791624\n",
      "Train:1 Epoch: 177 Eval_loss: 0.001082975184544921\n",
      "Train:1 Epoch: 178 Eval_loss: 0.0010494092712178826\n",
      "Train:1 Epoch: 179 Eval_loss: 0.0010325448820367455\n",
      "Train:1 Epoch: 180 Eval_loss: 0.001051009981893003\n",
      "Train:1 Epoch: 181 Eval_loss: 0.0010291062062606215\n",
      "Train:1 Epoch: 182 Eval_loss: 0.001083152019418776\n",
      "Train:1 Epoch: 183 Eval_loss: 0.0010158109944313765\n",
      "Train:1 Epoch: 184 Eval_loss: 0.0010620707180351019\n",
      "Train:1 Epoch: 185 Eval_loss: 0.0013792670797556639\n",
      "Train:1 Epoch: 186 Eval_loss: 0.0011368824634701014\n",
      "Train:1 Epoch: 187 Eval_loss: 0.0011287843808531761\n",
      "Train:1 Epoch: 188 Eval_loss: 0.001151183620095253\n",
      "Train:1 Epoch: 189 Eval_loss: 0.0010592661565169692\n",
      "Train:1 Epoch: 190 Eval_loss: 0.0009873671224340796\n",
      "Train:1 Epoch: 191 Eval_loss: 0.0009793812641873956\n",
      "Train:1 Epoch: 192 Eval_loss: 0.0009471122175455093\n",
      "Train:1 Epoch: 193 Eval_loss: 0.0009248789283446968\n",
      "Train:1 Epoch: 194 Eval_loss: 0.0009233147720806301\n",
      "Train:1 Epoch: 195 Eval_loss: 0.000891099392902106\n",
      "Train:1 Epoch: 196 Eval_loss: 0.0009186951792798936\n",
      "Train:1 Epoch: 197 Eval_loss: 0.000879399012774229\n",
      "Train:1 Epoch: 198 Eval_loss: 0.0008654982666485012\n",
      "Train:1 Epoch: 199 Eval_loss: 0.0008884448907338083\n",
      "Train:1 Epoch: 200 Eval_loss: 0.0008925875299610198\n",
      "Train:1 Epoch: 201 Eval_loss: 0.0009052191744558513\n",
      "Train:1 Epoch: 202 Eval_loss: 0.0008713281713426113\n",
      "Train:1 Epoch: 203 Eval_loss: 0.0010021681664511561\n",
      "Train:1 Epoch: 204 Eval_loss: 0.0008626158232800663\n",
      "Train:1 Epoch: 205 Eval_loss: 0.0008865623385645449\n",
      "Train:1 Epoch: 206 Eval_loss: 0.0008660629391670227\n",
      "Train:1 Epoch: 207 Eval_loss: 0.000926833541598171\n",
      "Train:1 Epoch: 208 Eval_loss: 0.0009221155778504908\n",
      "Train:1 Epoch: 209 Eval_loss: 0.0008979539852589369\n",
      "Train:1 Epoch: 210 Eval_loss: 0.0009487930219620466\n",
      "Train:1 Epoch: 211 Eval_loss: 0.0009007310727611184\n",
      "Train:1 Epoch: 212 Eval_loss: 0.0008675265125930309\n",
      "Train:1 Epoch: 213 Eval_loss: 0.0009504497284069657\n",
      "Train:1 Epoch: 214 Eval_loss: 0.0008274175925180316\n",
      "Train:1 Epoch: 215 Eval_loss: 0.0008667099755257368\n",
      "Train:1 Epoch: 216 Eval_loss: 0.0009793741628527641\n",
      "Train:1 Epoch: 217 Eval_loss: 0.000981468241661787\n",
      "Train:1 Epoch: 218 Eval_loss: 0.0008994966628961265\n",
      "Train:1 Epoch: 219 Eval_loss: 0.0008739694603718817\n",
      "Train:1 Epoch: 220 Eval_loss: 0.0008486488368362188\n",
      "Train:1 Epoch: 221 Eval_loss: 0.0007867212407290936\n",
      "Train:1 Epoch: 222 Eval_loss: 0.0008134531672112644\n",
      "Train:1 Epoch: 223 Eval_loss: 0.000843311136122793\n",
      "Train:1 Epoch: 224 Eval_loss: 0.0008339792839251459\n",
      "Train:1 Epoch: 225 Eval_loss: 0.000829788448754698\n",
      "Train:1 Epoch: 226 Eval_loss: 0.0007643702556379139\n",
      "Train:1 Epoch: 227 Eval_loss: 0.0007314921822398901\n",
      "Train:1 Epoch: 228 Eval_loss: 0.0007267769542522728\n",
      "Train:1 Epoch: 229 Eval_loss: 0.0007063792436383665\n",
      "Train:1 Epoch: 230 Eval_loss: 0.0006840784335508943\n",
      "Train:1 Epoch: 231 Eval_loss: 0.00070163793861866\n",
      "Train:1 Epoch: 232 Eval_loss: 0.0007213195785880089\n",
      "Train:1 Epoch: 233 Eval_loss: 0.0007329359068535268\n",
      "Train:1 Epoch: 234 Eval_loss: 0.0007065558456815779\n",
      "Train:1 Epoch: 235 Eval_loss: 0.0006927843205630779\n",
      "Train:1 Epoch: 236 Eval_loss: 0.0007968873251229525\n",
      "Train:1 Epoch: 237 Eval_loss: 0.0007659249240532517\n",
      "Train:1 Epoch: 238 Eval_loss: 0.0007903054356575012\n",
      "Train:1 Epoch: 239 Eval_loss: 0.0007948644342832267\n",
      "Train:2 Epoch: 0 Eval_loss: 0.06507420539855957\n",
      "Train:2 Epoch: 1 Eval_loss: 0.033434268087148666\n",
      "Train:2 Epoch: 2 Eval_loss: 0.027912912890315056\n",
      "Train:2 Epoch: 3 Eval_loss: 0.019554460421204567\n",
      "Train:2 Epoch: 4 Eval_loss: 0.01977589540183544\n",
      "Train:2 Epoch: 5 Eval_loss: 0.01841045916080475\n",
      "Train:2 Epoch: 6 Eval_loss: 0.016915753483772278\n",
      "Train:2 Epoch: 7 Eval_loss: 0.01628975383937359\n",
      "Train:2 Epoch: 8 Eval_loss: 0.015218035317957401\n",
      "Train:2 Epoch: 9 Eval_loss: 0.015435165725648403\n",
      "Train:2 Epoch: 10 Eval_loss: 0.013021818362176418\n",
      "Train:2 Epoch: 11 Eval_loss: 0.011710437014698982\n",
      "Train:2 Epoch: 12 Eval_loss: 0.010940921492874622\n",
      "Train:2 Epoch: 13 Eval_loss: 0.009647109545767307\n",
      "Train:2 Epoch: 14 Eval_loss: 0.00932748056948185\n",
      "Train:2 Epoch: 15 Eval_loss: 0.009248141199350357\n",
      "Train:2 Epoch: 16 Eval_loss: 0.008541165851056576\n",
      "Train:2 Epoch: 17 Eval_loss: 0.008759042248129845\n",
      "Train:2 Epoch: 18 Eval_loss: 0.008579447865486145\n",
      "Train:2 Epoch: 19 Eval_loss: 0.008297446183860302\n",
      "Train:2 Epoch: 20 Eval_loss: 0.008472729474306107\n",
      "Train:2 Epoch: 21 Eval_loss: 0.007954485714435577\n",
      "Train:2 Epoch: 22 Eval_loss: 0.007707864046096802\n",
      "Train:2 Epoch: 23 Eval_loss: 0.007486488204449415\n",
      "Train:2 Epoch: 24 Eval_loss: 0.0073939221911132336\n",
      "Train:2 Epoch: 25 Eval_loss: 0.006945708766579628\n",
      "Train:2 Epoch: 26 Eval_loss: 0.006875448860228062\n",
      "Train:2 Epoch: 27 Eval_loss: 0.006500792223960161\n",
      "Train:2 Epoch: 28 Eval_loss: 0.006314144004136324\n",
      "Train:2 Epoch: 29 Eval_loss: 0.006419307552278042\n",
      "Train:2 Epoch: 30 Eval_loss: 0.006188033614307642\n",
      "Train:2 Epoch: 31 Eval_loss: 0.006269755307585001\n",
      "Train:2 Epoch: 32 Eval_loss: 0.005682029761373997\n",
      "Train:2 Epoch: 33 Eval_loss: 0.005673243198543787\n",
      "Train:2 Epoch: 34 Eval_loss: 0.005284609738737345\n",
      "Train:2 Epoch: 35 Eval_loss: 0.005300809629261494\n",
      "Train:2 Epoch: 36 Eval_loss: 0.005376665852963924\n",
      "Train:2 Epoch: 37 Eval_loss: 0.005252827424556017\n",
      "Train:2 Epoch: 38 Eval_loss: 0.0050706034526228905\n",
      "Train:2 Epoch: 39 Eval_loss: 0.00475182943046093\n",
      "Train:2 Epoch: 40 Eval_loss: 0.004867760930210352\n",
      "Train:2 Epoch: 41 Eval_loss: 0.004695876967161894\n",
      "Train:2 Epoch: 42 Eval_loss: 0.0043767658062279224\n",
      "Train:2 Epoch: 43 Eval_loss: 0.004398299381136894\n",
      "Train:2 Epoch: 44 Eval_loss: 0.004443347919732332\n",
      "Train:2 Epoch: 45 Eval_loss: 0.0043421522714197636\n",
      "Train:2 Epoch: 46 Eval_loss: 0.004316683858633041\n",
      "Train:2 Epoch: 47 Eval_loss: 0.00426299637183547\n",
      "Train:2 Epoch: 48 Eval_loss: 0.004255356267094612\n",
      "Train:2 Epoch: 49 Eval_loss: 0.0042238784953951836\n",
      "Train:2 Epoch: 50 Eval_loss: 0.0041869874112308025\n",
      "Train:2 Epoch: 51 Eval_loss: 0.004278565291315317\n",
      "Train:2 Epoch: 52 Eval_loss: 0.004346188623458147\n",
      "Train:2 Epoch: 53 Eval_loss: 0.004240663722157478\n",
      "Train:2 Epoch: 54 Eval_loss: 0.0041206106543540955\n",
      "Train:2 Epoch: 55 Eval_loss: 0.004179087933152914\n",
      "Train:2 Epoch: 56 Eval_loss: 0.004214954096823931\n",
      "Train:2 Epoch: 57 Eval_loss: 0.004171914421021938\n",
      "Train:2 Epoch: 58 Eval_loss: 0.004085430409759283\n",
      "Train:2 Epoch: 59 Eval_loss: 0.004113842733204365\n",
      "Train:2 Epoch: 60 Eval_loss: 0.0039878711104393005\n",
      "Train:2 Epoch: 61 Eval_loss: 0.004018573090434074\n",
      "Train:2 Epoch: 62 Eval_loss: 0.003892149543389678\n",
      "Train:2 Epoch: 63 Eval_loss: 0.003945621661841869\n",
      "Train:2 Epoch: 64 Eval_loss: 0.003727359464392066\n",
      "Train:2 Epoch: 65 Eval_loss: 0.003806011052802205\n",
      "Train:2 Epoch: 66 Eval_loss: 0.003763679414987564\n",
      "Train:2 Epoch: 67 Eval_loss: 0.0037840609438717365\n",
      "Train:2 Epoch: 68 Eval_loss: 0.0036940674763172865\n",
      "Train:2 Epoch: 69 Eval_loss: 0.00361726270057261\n",
      "Train:2 Epoch: 70 Eval_loss: 0.0037019378505647182\n",
      "Train:2 Epoch: 71 Eval_loss: 0.0036256161984056234\n",
      "Train:2 Epoch: 72 Eval_loss: 0.003370635909959674\n",
      "Train:2 Epoch: 73 Eval_loss: 0.003326281439512968\n",
      "Train:2 Epoch: 74 Eval_loss: 0.0032733730040490627\n",
      "Train:2 Epoch: 75 Eval_loss: 0.003194142132997513\n",
      "Train:2 Epoch: 76 Eval_loss: 0.0032460279762744904\n",
      "Train:2 Epoch: 77 Eval_loss: 0.003113157581537962\n",
      "Train:2 Epoch: 78 Eval_loss: 0.003214476862922311\n",
      "Train:2 Epoch: 79 Eval_loss: 0.003256621304899454\n",
      "Train:2 Epoch: 80 Eval_loss: 0.0031880103051662445\n",
      "Train:2 Epoch: 81 Eval_loss: 0.0029545770958065987\n",
      "Train:2 Epoch: 82 Eval_loss: 0.002934312215074897\n",
      "Train:2 Epoch: 83 Eval_loss: 0.002970499685034156\n",
      "Train:2 Epoch: 84 Eval_loss: 0.0028012043330818415\n",
      "Train:2 Epoch: 85 Eval_loss: 0.0029085904825478792\n",
      "Train:2 Epoch: 86 Eval_loss: 0.002903589280322194\n",
      "Train:2 Epoch: 87 Eval_loss: 0.0028519693296402693\n",
      "Train:2 Epoch: 88 Eval_loss: 0.002744261408224702\n",
      "Train:2 Epoch: 89 Eval_loss: 0.0027155678253620863\n",
      "Train:2 Epoch: 90 Eval_loss: 0.0028167690616101027\n",
      "Train:2 Epoch: 91 Eval_loss: 0.0027314817998558283\n",
      "Train:2 Epoch: 92 Eval_loss: 0.002734928159043193\n",
      "Train:2 Epoch: 93 Eval_loss: 0.002715850016102195\n",
      "Train:2 Epoch: 94 Eval_loss: 0.0025286341551691294\n",
      "Train:2 Epoch: 95 Eval_loss: 0.0025386596098542213\n",
      "Train:2 Epoch: 96 Eval_loss: 0.0024262862280011177\n",
      "Train:2 Epoch: 97 Eval_loss: 0.002419924596324563\n",
      "Train:2 Epoch: 98 Eval_loss: 0.002332029864192009\n",
      "Train:2 Epoch: 99 Eval_loss: 0.002333319978788495\n",
      "Train:2 Epoch: 100 Eval_loss: 0.002336754696443677\n",
      "Train:2 Epoch: 101 Eval_loss: 0.00239370740018785\n",
      "Train:2 Epoch: 102 Eval_loss: 0.0023524139542132616\n",
      "Train:2 Epoch: 103 Eval_loss: 0.0022974698804318905\n",
      "Train:2 Epoch: 104 Eval_loss: 0.00228457641787827\n",
      "Train:2 Epoch: 105 Eval_loss: 0.0023314065765589476\n",
      "Train:2 Epoch: 106 Eval_loss: 0.0022186164278537035\n",
      "Train:2 Epoch: 107 Eval_loss: 0.00227081379853189\n",
      "Train:2 Epoch: 108 Eval_loss: 0.0022600064985454082\n",
      "Train:2 Epoch: 109 Eval_loss: 0.002206044504418969\n",
      "Train:2 Epoch: 110 Eval_loss: 0.002258450258523226\n",
      "Train:2 Epoch: 111 Eval_loss: 0.002179680857807398\n",
      "Train:2 Epoch: 112 Eval_loss: 0.0021167343948036432\n",
      "Train:2 Epoch: 113 Eval_loss: 0.0020926096476614475\n",
      "Train:2 Epoch: 114 Eval_loss: 0.002083579543977976\n",
      "Train:2 Epoch: 115 Eval_loss: 0.00206460221670568\n",
      "Train:2 Epoch: 116 Eval_loss: 0.0021326597779989243\n",
      "Train:2 Epoch: 117 Eval_loss: 0.0021698966156691313\n",
      "Train:2 Epoch: 118 Eval_loss: 0.0021523579489439726\n",
      "Train:2 Epoch: 119 Eval_loss: 0.002129865810275078\n",
      "Train:2 Epoch: 120 Eval_loss: 0.00211502006277442\n",
      "Train:2 Epoch: 121 Eval_loss: 0.0020285598002374172\n",
      "Train:2 Epoch: 122 Eval_loss: 0.002002849243581295\n",
      "Train:2 Epoch: 123 Eval_loss: 0.001966577721759677\n",
      "Train:2 Epoch: 124 Eval_loss: 0.0018778557423502207\n",
      "Train:2 Epoch: 125 Eval_loss: 0.0019069983391091228\n",
      "Train:2 Epoch: 126 Eval_loss: 0.0019184380071237683\n",
      "Train:2 Epoch: 127 Eval_loss: 0.0018635186133906245\n",
      "Train:2 Epoch: 128 Eval_loss: 0.0018914274405688047\n",
      "Train:2 Epoch: 129 Eval_loss: 0.0018422954017296433\n",
      "Train:2 Epoch: 130 Eval_loss: 0.0018415988888591528\n",
      "Train:2 Epoch: 131 Eval_loss: 0.001912263804115355\n",
      "Train:2 Epoch: 132 Eval_loss: 0.0017530324403196573\n",
      "Train:2 Epoch: 133 Eval_loss: 0.0017062422120943666\n",
      "Train:2 Epoch: 134 Eval_loss: 0.001649369951337576\n",
      "Train:2 Epoch: 135 Eval_loss: 0.0015882658772170544\n",
      "Train:2 Epoch: 136 Eval_loss: 0.0016623263945803046\n",
      "Train:2 Epoch: 137 Eval_loss: 0.0016104623209685087\n",
      "Train:2 Epoch: 138 Eval_loss: 0.0016302262665703893\n",
      "Train:2 Epoch: 139 Eval_loss: 0.0015653531299903989\n",
      "Train:2 Epoch: 140 Eval_loss: 0.00159432680811733\n",
      "Train:2 Epoch: 141 Eval_loss: 0.0015727950958535075\n",
      "Train:2 Epoch: 142 Eval_loss: 0.0015409947372972965\n",
      "Train:2 Epoch: 143 Eval_loss: 0.0015779453096911311\n",
      "Train:2 Epoch: 144 Eval_loss: 0.0015071381349116564\n",
      "Train:2 Epoch: 145 Eval_loss: 0.0015507991192862391\n",
      "Train:2 Epoch: 146 Eval_loss: 0.0015252369921654463\n",
      "Train:2 Epoch: 147 Eval_loss: 0.0015000643907114863\n",
      "Train:2 Epoch: 148 Eval_loss: 0.0014980804407969117\n",
      "Train:2 Epoch: 149 Eval_loss: 0.0014328145189210773\n",
      "Train:2 Epoch: 150 Eval_loss: 0.0013417063746601343\n",
      "Train:2 Epoch: 151 Eval_loss: 0.0013132378226146102\n",
      "Train:2 Epoch: 152 Eval_loss: 0.0013165395939722657\n",
      "Train:2 Epoch: 153 Eval_loss: 0.0012772640911862254\n",
      "Train:2 Epoch: 154 Eval_loss: 0.0013462187489494681\n",
      "Train:2 Epoch: 155 Eval_loss: 0.0013160959351807833\n",
      "Train:2 Epoch: 156 Eval_loss: 0.0014959342079237103\n",
      "Train:2 Epoch: 157 Eval_loss: 0.0014371612342074513\n",
      "Train:2 Epoch: 158 Eval_loss: 0.0013932123547419906\n",
      "Train:2 Epoch: 159 Eval_loss: 0.001298117800615728\n",
      "Train:2 Epoch: 160 Eval_loss: 0.0013607509899884462\n",
      "Train:2 Epoch: 161 Eval_loss: 0.001282618846744299\n",
      "Train:2 Epoch: 162 Eval_loss: 0.0012602685019373894\n",
      "Train:2 Epoch: 163 Eval_loss: 0.0013105303514748812\n",
      "Train:2 Epoch: 164 Eval_loss: 0.0013971991138532758\n",
      "Train:2 Epoch: 165 Eval_loss: 0.001265136175788939\n",
      "Train:2 Epoch: 166 Eval_loss: 0.0012914770049974322\n",
      "Train:2 Epoch: 167 Eval_loss: 0.0012258016504347324\n",
      "Train:2 Epoch: 168 Eval_loss: 0.001207881374284625\n",
      "Train:2 Epoch: 169 Eval_loss: 0.0012448277557268739\n",
      "Train:2 Epoch: 170 Eval_loss: 0.0011712644482031465\n",
      "Train:2 Epoch: 171 Eval_loss: 0.0012216165196150541\n",
      "Train:2 Epoch: 172 Eval_loss: 0.0012204033555462956\n",
      "Train:2 Epoch: 173 Eval_loss: 0.0011651618406176567\n",
      "Train:2 Epoch: 174 Eval_loss: 0.0011801765067502856\n",
      "Train:2 Epoch: 175 Eval_loss: 0.0011990760685876012\n",
      "Train:2 Epoch: 176 Eval_loss: 0.001151831354945898\n",
      "Train:2 Epoch: 177 Eval_loss: 0.0010693816002458334\n",
      "Train:2 Epoch: 178 Eval_loss: 0.0011252773692831397\n",
      "Train:2 Epoch: 179 Eval_loss: 0.0010757329873740673\n",
      "Train:2 Epoch: 180 Eval_loss: 0.001049016136676073\n",
      "Train:2 Epoch: 181 Eval_loss: 0.0009957434376701713\n",
      "Train:2 Epoch: 182 Eval_loss: 0.001064051641151309\n",
      "Train:2 Epoch: 183 Eval_loss: 0.0010901852510869503\n",
      "Train:2 Epoch: 184 Eval_loss: 0.0009948632214218378\n",
      "Train:2 Epoch: 185 Eval_loss: 0.001000403193756938\n",
      "Train:2 Epoch: 186 Eval_loss: 0.0009432195220142603\n",
      "Train:2 Epoch: 187 Eval_loss: 0.001017923466861248\n",
      "Train:2 Epoch: 188 Eval_loss: 0.001051726983860135\n",
      "Train:2 Epoch: 189 Eval_loss: 0.001010945881716907\n",
      "Train:2 Epoch: 190 Eval_loss: 0.0010479746852070093\n",
      "Train:2 Epoch: 191 Eval_loss: 0.0009499440784566104\n",
      "Train:2 Epoch: 192 Eval_loss: 0.001011557411402464\n",
      "Train:2 Epoch: 193 Eval_loss: 0.001003267359919846\n",
      "Train:2 Epoch: 194 Eval_loss: 0.0010034114820882678\n",
      "Train:2 Epoch: 195 Eval_loss: 0.0009969937382265925\n",
      "Train:3 Epoch: 0 Eval_loss: 0.08619102835655212\n",
      "Train:3 Epoch: 1 Eval_loss: 0.03453676775097847\n",
      "Train:3 Epoch: 2 Eval_loss: 0.02824460342526436\n",
      "Train:3 Epoch: 3 Eval_loss: 0.021438246592879295\n",
      "Train:3 Epoch: 4 Eval_loss: 0.019369669258594513\n",
      "Train:3 Epoch: 5 Eval_loss: 0.01835324801504612\n",
      "Train:3 Epoch: 6 Eval_loss: 0.017335087060928345\n",
      "Train:3 Epoch: 7 Eval_loss: 0.016017626971006393\n",
      "Train:3 Epoch: 8 Eval_loss: 0.01504048053175211\n",
      "Train:3 Epoch: 9 Eval_loss: 0.014594944193959236\n",
      "Train:3 Epoch: 10 Eval_loss: 0.013982833363115788\n",
      "Train:3 Epoch: 11 Eval_loss: 0.013197244144976139\n",
      "Train:3 Epoch: 12 Eval_loss: 0.012247045524418354\n",
      "Train:3 Epoch: 13 Eval_loss: 0.011494827456772327\n",
      "Train:3 Epoch: 14 Eval_loss: 0.010476866737008095\n",
      "Train:3 Epoch: 15 Eval_loss: 0.01007391232997179\n",
      "Train:3 Epoch: 16 Eval_loss: 0.009928708896040916\n",
      "Train:3 Epoch: 17 Eval_loss: 0.009519780986011028\n",
      "Train:3 Epoch: 18 Eval_loss: 0.009353206492960453\n",
      "Train:3 Epoch: 19 Eval_loss: 0.009406452998518944\n",
      "Train:3 Epoch: 20 Eval_loss: 0.009275844320654869\n",
      "Train:3 Epoch: 21 Eval_loss: 0.009034479968249798\n",
      "Train:3 Epoch: 22 Eval_loss: 0.009007268585264683\n",
      "Train:3 Epoch: 23 Eval_loss: 0.00876531470566988\n",
      "Train:3 Epoch: 24 Eval_loss: 0.0087332334369421\n",
      "Train:3 Epoch: 25 Eval_loss: 0.008428565226495266\n",
      "Train:3 Epoch: 26 Eval_loss: 0.008318448439240456\n",
      "Train:3 Epoch: 27 Eval_loss: 0.008154895156621933\n",
      "Train:3 Epoch: 28 Eval_loss: 0.007853584364056587\n",
      "Train:3 Epoch: 29 Eval_loss: 0.007877344265580177\n",
      "Train:3 Epoch: 30 Eval_loss: 0.007861456833779812\n",
      "Train:3 Epoch: 31 Eval_loss: 0.007842031307518482\n",
      "Train:3 Epoch: 32 Eval_loss: 0.0076844110153615475\n",
      "Train:3 Epoch: 33 Eval_loss: 0.0074567124247550964\n",
      "Train:3 Epoch: 34 Eval_loss: 0.0074853538535535336\n",
      "Train:3 Epoch: 35 Eval_loss: 0.0074294921942055225\n",
      "Train:3 Epoch: 36 Eval_loss: 0.007434272672981024\n",
      "Train:3 Epoch: 37 Eval_loss: 0.007155430503189564\n",
      "Train:3 Epoch: 38 Eval_loss: 0.006975620985031128\n",
      "Train:3 Epoch: 39 Eval_loss: 0.006766832433640957\n",
      "Train:3 Epoch: 40 Eval_loss: 0.006849103141576052\n",
      "Train:3 Epoch: 41 Eval_loss: 0.006806019227951765\n",
      "Train:3 Epoch: 42 Eval_loss: 0.006692387629300356\n",
      "Train:3 Epoch: 43 Eval_loss: 0.006543015129864216\n",
      "Train:3 Epoch: 44 Eval_loss: 0.006331589072942734\n",
      "Train:3 Epoch: 45 Eval_loss: 0.006331076845526695\n",
      "Train:3 Epoch: 46 Eval_loss: 0.006286423187702894\n",
      "Train:3 Epoch: 47 Eval_loss: 0.006158692762255669\n",
      "Train:3 Epoch: 48 Eval_loss: 0.006088977679610252\n",
      "Train:3 Epoch: 49 Eval_loss: 0.006056405603885651\n",
      "Train:3 Epoch: 50 Eval_loss: 0.006032941397279501\n",
      "Train:3 Epoch: 51 Eval_loss: 0.005849938374012709\n",
      "Train:3 Epoch: 52 Eval_loss: 0.005708666052669287\n",
      "Train:3 Epoch: 53 Eval_loss: 0.005554370116442442\n",
      "Train:3 Epoch: 54 Eval_loss: 0.005534627474844456\n",
      "Train:3 Epoch: 55 Eval_loss: 0.005414131097495556\n",
      "Train:3 Epoch: 56 Eval_loss: 0.005408274941146374\n",
      "Train:3 Epoch: 57 Eval_loss: 0.005432876758277416\n",
      "Train:3 Epoch: 58 Eval_loss: 0.005247535649687052\n",
      "Train:3 Epoch: 59 Eval_loss: 0.0050962925888597965\n",
      "Train:3 Epoch: 60 Eval_loss: 0.005161550361663103\n",
      "Train:3 Epoch: 61 Eval_loss: 0.0051194834522902966\n",
      "Train:3 Epoch: 62 Eval_loss: 0.005066115874797106\n",
      "Train:3 Epoch: 63 Eval_loss: 0.004955227952450514\n",
      "Train:3 Epoch: 64 Eval_loss: 0.004986313171684742\n",
      "Train:3 Epoch: 65 Eval_loss: 0.004965739790350199\n",
      "Train:3 Epoch: 66 Eval_loss: 0.0048825121484696865\n",
      "Train:3 Epoch: 67 Eval_loss: 0.004844309762120247\n",
      "Train:3 Epoch: 68 Eval_loss: 0.0047561656683683395\n",
      "Train:3 Epoch: 69 Eval_loss: 0.0045705148950219154\n",
      "Train:3 Epoch: 70 Eval_loss: 0.004479427821934223\n",
      "Train:3 Epoch: 71 Eval_loss: 0.004553140606731176\n",
      "Train:3 Epoch: 72 Eval_loss: 0.0044514499604702\n",
      "Train:3 Epoch: 73 Eval_loss: 0.004320742562413216\n",
      "Train:3 Epoch: 74 Eval_loss: 0.004378029145300388\n",
      "Train:3 Epoch: 75 Eval_loss: 0.0044495295733213425\n",
      "Train:3 Epoch: 76 Eval_loss: 0.004392743110656738\n",
      "Train:3 Epoch: 77 Eval_loss: 0.004203811753541231\n",
      "Train:3 Epoch: 78 Eval_loss: 0.004242973402142525\n",
      "Train:3 Epoch: 79 Eval_loss: 0.004203110001981258\n",
      "Train:3 Epoch: 80 Eval_loss: 0.004116341937333345\n",
      "Train:3 Epoch: 81 Eval_loss: 0.004045456647872925\n",
      "Train:3 Epoch: 82 Eval_loss: 0.003970488905906677\n",
      "Train:3 Epoch: 83 Eval_loss: 0.0038509818259626627\n",
      "Train:3 Epoch: 84 Eval_loss: 0.003973572514951229\n",
      "Train:3 Epoch: 85 Eval_loss: 0.0039437334053218365\n",
      "Train:3 Epoch: 86 Eval_loss: 0.0037633106112480164\n",
      "Train:3 Epoch: 87 Eval_loss: 0.003722386434674263\n",
      "Train:3 Epoch: 88 Eval_loss: 0.0037692703772336245\n",
      "Train:3 Epoch: 89 Eval_loss: 0.0036367089487612247\n",
      "Train:3 Epoch: 90 Eval_loss: 0.003571961773559451\n",
      "Train:3 Epoch: 91 Eval_loss: 0.003600230673328042\n",
      "Train:3 Epoch: 92 Eval_loss: 0.003450034186244011\n",
      "Train:3 Epoch: 93 Eval_loss: 0.0033995506819337606\n",
      "Train:3 Epoch: 94 Eval_loss: 0.0034448010846972466\n",
      "Train:3 Epoch: 95 Eval_loss: 0.0033701180946081877\n",
      "Train:3 Epoch: 96 Eval_loss: 0.003351742634549737\n",
      "Train:3 Epoch: 97 Eval_loss: 0.0033413441851735115\n",
      "Train:3 Epoch: 98 Eval_loss: 0.0032629366032779217\n",
      "Train:3 Epoch: 99 Eval_loss: 0.003205158282071352\n",
      "Train:3 Epoch: 100 Eval_loss: 0.0031525769736617804\n",
      "Train:3 Epoch: 101 Eval_loss: 0.003152481745928526\n",
      "Train:3 Epoch: 102 Eval_loss: 0.003117963904514909\n",
      "Train:3 Epoch: 103 Eval_loss: 0.0031240996904671192\n",
      "Train:3 Epoch: 104 Eval_loss: 0.003022645367309451\n",
      "Train:3 Epoch: 105 Eval_loss: 0.0030893408693373203\n",
      "Train:3 Epoch: 106 Eval_loss: 0.0030744122341275215\n",
      "Train:3 Epoch: 107 Eval_loss: 0.0030691383872181177\n",
      "Train:3 Epoch: 108 Eval_loss: 0.002966806758195162\n",
      "Train:3 Epoch: 109 Eval_loss: 0.0029922632966190577\n",
      "Train:3 Epoch: 110 Eval_loss: 0.002965632826089859\n",
      "Train:3 Epoch: 111 Eval_loss: 0.0029460371006280184\n",
      "Train:3 Epoch: 112 Eval_loss: 0.0028747820761054754\n",
      "Train:3 Epoch: 113 Eval_loss: 0.0028268718160688877\n",
      "Train:3 Epoch: 114 Eval_loss: 0.002780246315523982\n",
      "Train:3 Epoch: 115 Eval_loss: 0.0027601919136941433\n",
      "Train:3 Epoch: 116 Eval_loss: 0.002759432652965188\n",
      "Train:3 Epoch: 117 Eval_loss: 0.002700845478102565\n",
      "Train:3 Epoch: 118 Eval_loss: 0.002704064827412367\n",
      "Train:3 Epoch: 119 Eval_loss: 0.002691807923838496\n",
      "Train:3 Epoch: 120 Eval_loss: 0.0027469417545944452\n",
      "Train:3 Epoch: 121 Eval_loss: 0.0026438829954713583\n",
      "Train:3 Epoch: 122 Eval_loss: 0.002621703315526247\n",
      "Train:3 Epoch: 123 Eval_loss: 0.0025517139583826065\n",
      "Train:3 Epoch: 124 Eval_loss: 0.002526589436456561\n",
      "Train:3 Epoch: 125 Eval_loss: 0.002581836888566613\n",
      "Train:3 Epoch: 126 Eval_loss: 0.0025698384270071983\n",
      "Train:3 Epoch: 127 Eval_loss: 0.0024703165981918573\n",
      "Train:3 Epoch: 128 Eval_loss: 0.0024191602133214474\n",
      "Train:3 Epoch: 129 Eval_loss: 0.0023767577949911356\n",
      "Train:3 Epoch: 130 Eval_loss: 0.00236289924941957\n",
      "Train:3 Epoch: 131 Eval_loss: 0.0023462981916964054\n",
      "Train:3 Epoch: 132 Eval_loss: 0.002295216778293252\n",
      "Train:3 Epoch: 133 Eval_loss: 0.0022203584667295218\n",
      "Train:3 Epoch: 134 Eval_loss: 0.002249788958579302\n",
      "Train:3 Epoch: 135 Eval_loss: 0.0022034705616533756\n",
      "Train:3 Epoch: 136 Eval_loss: 0.0021915072575211525\n",
      "Train:3 Epoch: 137 Eval_loss: 0.002203505951911211\n",
      "Train:3 Epoch: 138 Eval_loss: 0.0021543644834309816\n",
      "Train:3 Epoch: 139 Eval_loss: 0.0021191388368606567\n",
      "Train:3 Epoch: 140 Eval_loss: 0.0021232781000435352\n",
      "Train:3 Epoch: 141 Eval_loss: 0.002060860628262162\n",
      "Train:3 Epoch: 142 Eval_loss: 0.002085593296214938\n",
      "Train:3 Epoch: 143 Eval_loss: 0.0020646487828344107\n",
      "Train:3 Epoch: 144 Eval_loss: 0.0020192598458379507\n",
      "Train:3 Epoch: 145 Eval_loss: 0.002034535864368081\n",
      "Train:3 Epoch: 146 Eval_loss: 0.0020403373055160046\n",
      "Train:3 Epoch: 147 Eval_loss: 0.001994587481021881\n",
      "Train:3 Epoch: 148 Eval_loss: 0.0019694834481924772\n",
      "Train:3 Epoch: 149 Eval_loss: 0.0019410259556025267\n",
      "Train:3 Epoch: 150 Eval_loss: 0.00195050030015409\n",
      "Train:3 Epoch: 151 Eval_loss: 0.00198800559155643\n",
      "Train:3 Epoch: 152 Eval_loss: 0.002063153078779578\n",
      "Train:3 Epoch: 153 Eval_loss: 0.001960944617167115\n",
      "Train:3 Epoch: 154 Eval_loss: 0.001999984495341778\n",
      "Train:3 Epoch: 155 Eval_loss: 0.0019232564372941852\n",
      "Train:3 Epoch: 156 Eval_loss: 0.0018721061060205102\n",
      "Train:3 Epoch: 157 Eval_loss: 0.0018497395794838667\n",
      "Train:3 Epoch: 158 Eval_loss: 0.0018328003352507949\n",
      "Train:3 Epoch: 159 Eval_loss: 0.0018434718949720263\n",
      "Train:3 Epoch: 160 Eval_loss: 0.0017569861374795437\n",
      "Train:3 Epoch: 161 Eval_loss: 0.0017600166611373425\n",
      "Train:3 Epoch: 162 Eval_loss: 0.0017457943176850677\n",
      "Train:3 Epoch: 163 Eval_loss: 0.0017779229674488306\n",
      "Train:3 Epoch: 164 Eval_loss: 0.001686996198259294\n",
      "Train:3 Epoch: 165 Eval_loss: 0.0016915308078750968\n",
      "Train:3 Epoch: 166 Eval_loss: 0.0017035732744261622\n",
      "Train:3 Epoch: 167 Eval_loss: 0.001710622920654714\n",
      "Train:3 Epoch: 168 Eval_loss: 0.0017086175503209233\n",
      "Train:3 Epoch: 169 Eval_loss: 0.0016827743966132402\n",
      "Train:3 Epoch: 170 Eval_loss: 0.0017077464144676924\n",
      "Train:3 Epoch: 171 Eval_loss: 0.0016616573557257652\n",
      "Train:3 Epoch: 172 Eval_loss: 0.00168486381880939\n",
      "Train:3 Epoch: 173 Eval_loss: 0.0016093529993668199\n",
      "Train:3 Epoch: 174 Eval_loss: 0.0016022013733163476\n",
      "Train:3 Epoch: 175 Eval_loss: 0.0015461620641872287\n",
      "Train:3 Epoch: 176 Eval_loss: 0.0015353980707004666\n",
      "Train:3 Epoch: 177 Eval_loss: 0.001474018907174468\n",
      "Train:3 Epoch: 178 Eval_loss: 0.0014749257825314999\n",
      "Train:3 Epoch: 179 Eval_loss: 0.0014766285894438624\n",
      "Train:3 Epoch: 180 Eval_loss: 0.0015504321781918406\n",
      "Train:3 Epoch: 181 Eval_loss: 0.0015408527106046677\n",
      "Train:3 Epoch: 182 Eval_loss: 0.0015048411441966891\n",
      "Train:3 Epoch: 183 Eval_loss: 0.001513353898189962\n",
      "Train:3 Epoch: 184 Eval_loss: 0.0014780405908823013\n",
      "Train:3 Epoch: 185 Eval_loss: 0.0014741881750524044\n",
      "Train:3 Epoch: 186 Eval_loss: 0.0013755211839452386\n",
      "Train:3 Epoch: 187 Eval_loss: 0.001370602985844016\n",
      "Train:3 Epoch: 188 Eval_loss: 0.0013605969725176692\n",
      "Train:3 Epoch: 189 Eval_loss: 0.0014594501117244363\n",
      "Train:3 Epoch: 190 Eval_loss: 0.0014858662616461515\n",
      "Train:3 Epoch: 191 Eval_loss: 0.0013893258292227983\n",
      "Train:3 Epoch: 192 Eval_loss: 0.001375014428049326\n",
      "Train:3 Epoch: 193 Eval_loss: 0.0014130345080047846\n",
      "Train:3 Epoch: 194 Eval_loss: 0.0013939370401203632\n",
      "Train:3 Epoch: 195 Eval_loss: 0.001423086505383253\n",
      "Train:3 Epoch: 196 Eval_loss: 0.0013582328101620078\n",
      "Train:3 Epoch: 197 Eval_loss: 0.0013181953690946102\n",
      "Train:3 Epoch: 198 Eval_loss: 0.0014010828454047441\n",
      "Train:3 Epoch: 199 Eval_loss: 0.001302580931223929\n",
      "Train:3 Epoch: 200 Eval_loss: 0.0013116586487740278\n",
      "Train:3 Epoch: 201 Eval_loss: 0.0012437114492058754\n",
      "Train:3 Epoch: 202 Eval_loss: 0.0012674382887780666\n",
      "Train:3 Epoch: 203 Eval_loss: 0.001253379974514246\n",
      "Train:3 Epoch: 204 Eval_loss: 0.00128835067152977\n",
      "Train:3 Epoch: 205 Eval_loss: 0.001226649503223598\n",
      "Train:3 Epoch: 206 Eval_loss: 0.0012211126741021872\n",
      "Train:3 Epoch: 207 Eval_loss: 0.001208195579238236\n",
      "Train:3 Epoch: 208 Eval_loss: 0.0011817950289696455\n",
      "Train:3 Epoch: 209 Eval_loss: 0.0011874022893607616\n",
      "Train:3 Epoch: 210 Eval_loss: 0.001161097432486713\n",
      "Train:3 Epoch: 211 Eval_loss: 0.0011241389438509941\n",
      "Train:3 Epoch: 212 Eval_loss: 0.0011163881281390786\n",
      "Train:3 Epoch: 213 Eval_loss: 0.0010955126490443945\n",
      "Train:3 Epoch: 214 Eval_loss: 0.0011303913779556751\n",
      "Train:3 Epoch: 215 Eval_loss: 0.0011332842987030745\n",
      "Train:3 Epoch: 216 Eval_loss: 0.0011206717463210225\n",
      "Train:3 Epoch: 217 Eval_loss: 0.0010602340335026383\n",
      "Train:3 Epoch: 218 Eval_loss: 0.001117304083891213\n",
      "Train:3 Epoch: 219 Eval_loss: 0.0010609078453853726\n",
      "Train:3 Epoch: 220 Eval_loss: 0.0010777608258649707\n",
      "Train:3 Epoch: 221 Eval_loss: 0.0010584997944533825\n",
      "Train:3 Epoch: 222 Eval_loss: 0.0010781021555885673\n",
      "Train:3 Epoch: 223 Eval_loss: 0.001250871573574841\n",
      "Train:3 Epoch: 224 Eval_loss: 0.0011965071316808462\n",
      "Train:3 Epoch: 225 Eval_loss: 0.0010991750750690699\n",
      "Train:3 Epoch: 226 Eval_loss: 0.0011868029832839966\n",
      "Train:3 Epoch: 227 Eval_loss: 0.0011147646000608802\n",
      "Train:3 Epoch: 228 Eval_loss: 0.0011181265581399202\n",
      "Train:3 Epoch: 229 Eval_loss: 0.001070724567398429\n",
      "Train:3 Epoch: 230 Eval_loss: 0.001038793590851128\n",
      "Train:3 Epoch: 231 Eval_loss: 0.0010203582933172584\n",
      "Train:3 Epoch: 232 Eval_loss: 0.0010387003421783447\n",
      "Train:3 Epoch: 233 Eval_loss: 0.0010584109695628285\n",
      "Train:3 Epoch: 234 Eval_loss: 0.0010301946895197034\n",
      "Train:3 Epoch: 235 Eval_loss: 0.0010366636561229825\n",
      "Train:3 Epoch: 236 Eval_loss: 0.0009580094483681023\n",
      "Train:3 Epoch: 237 Eval_loss: 0.0009519090526737273\n",
      "Train:3 Epoch: 238 Eval_loss: 0.0009478771826252341\n",
      "Train:3 Epoch: 239 Eval_loss: 0.0009229402639903128\n",
      "Train:3 Epoch: 240 Eval_loss: 0.0009124094503931701\n",
      "Train:3 Epoch: 241 Eval_loss: 0.0009186255047097802\n",
      "Train:3 Epoch: 242 Eval_loss: 0.0008496490772813559\n",
      "Train:3 Epoch: 243 Eval_loss: 0.0008501956472173333\n",
      "Train:3 Epoch: 244 Eval_loss: 0.0008389235590584576\n",
      "Train:3 Epoch: 245 Eval_loss: 0.0008531852508895099\n",
      "Train:3 Epoch: 246 Eval_loss: 0.0008876333595253527\n",
      "Train:3 Epoch: 247 Eval_loss: 0.0008643271867185831\n",
      "Train:3 Epoch: 248 Eval_loss: 0.0008654229459352791\n",
      "Train:3 Epoch: 249 Eval_loss: 0.0008641561726108193\n",
      "Train:3 Epoch: 250 Eval_loss: 0.0008316306630149484\n",
      "Train:3 Epoch: 251 Eval_loss: 0.0008489469764754176\n",
      "Train:3 Epoch: 252 Eval_loss: 0.0008408359135501087\n",
      "Train:3 Epoch: 253 Eval_loss: 0.0008553965017199516\n",
      "Train:3 Epoch: 254 Eval_loss: 0.0008539333939552307\n",
      "Train:3 Epoch: 255 Eval_loss: 0.0008443117840215564\n",
      "Train:3 Epoch: 256 Eval_loss: 0.0008138628909364343\n",
      "Train:3 Epoch: 257 Eval_loss: 0.0008674419950693846\n",
      "Train:3 Epoch: 258 Eval_loss: 0.0008634374826215208\n",
      "Train:3 Epoch: 259 Eval_loss: 0.0008737936150282621\n",
      "Train:3 Epoch: 260 Eval_loss: 0.0008204750483855605\n",
      "Train:3 Epoch: 261 Eval_loss: 0.0007733116508461535\n",
      "Train:3 Epoch: 262 Eval_loss: 0.0007841361220926046\n",
      "Train:3 Epoch: 263 Eval_loss: 0.0007610791944898665\n",
      "Train:3 Epoch: 264 Eval_loss: 0.0008428827859461308\n",
      "Train:3 Epoch: 265 Eval_loss: 0.0007711770012974739\n",
      "Train:3 Epoch: 266 Eval_loss: 0.0007585360435768962\n",
      "Train:3 Epoch: 267 Eval_loss: 0.0007480523781850934\n",
      "Train:3 Epoch: 268 Eval_loss: 0.0007506704423576593\n",
      "Train:3 Epoch: 269 Eval_loss: 0.0007614498026669025\n",
      "Train:3 Epoch: 270 Eval_loss: 0.0007249036571010947\n",
      "Train:3 Epoch: 271 Eval_loss: 0.0008749645785428584\n",
      "Train:3 Epoch: 272 Eval_loss: 0.0008233838016167283\n",
      "Train:3 Epoch: 273 Eval_loss: 0.0008559290436096489\n",
      "Train:3 Epoch: 274 Eval_loss: 0.0008595100953243673\n",
      "Train:3 Epoch: 275 Eval_loss: 0.0007484035450033844\n",
      "Train:3 Epoch: 276 Eval_loss: 0.0007399519090540707\n",
      "Train:3 Epoch: 277 Eval_loss: 0.0009177593747153878\n",
      "Train:3 Epoch: 278 Eval_loss: 0.0009983889758586884\n",
      "Train:3 Epoch: 279 Eval_loss: 0.0010671007912606\n",
      "Train:4 Epoch: 0 Eval_loss: 0.04819951951503754\n",
      "Train:4 Epoch: 1 Eval_loss: 0.026456298306584358\n",
      "Train:4 Epoch: 2 Eval_loss: 0.02029760368168354\n",
      "Train:4 Epoch: 3 Eval_loss: 0.015850024297833443\n",
      "Train:4 Epoch: 4 Eval_loss: 0.0144426254555583\n",
      "Train:4 Epoch: 5 Eval_loss: 0.012418029829859734\n",
      "Train:4 Epoch: 6 Eval_loss: 0.011416397988796234\n",
      "Train:4 Epoch: 7 Eval_loss: 0.010300030000507832\n",
      "Train:4 Epoch: 8 Eval_loss: 0.009693152271211147\n",
      "Train:4 Epoch: 9 Eval_loss: 0.009246010333299637\n",
      "Train:4 Epoch: 10 Eval_loss: 0.008945440873503685\n",
      "Train:4 Epoch: 11 Eval_loss: 0.008378048427402973\n",
      "Train:4 Epoch: 12 Eval_loss: 0.007898740470409393\n",
      "Train:4 Epoch: 13 Eval_loss: 0.0071713849902153015\n",
      "Train:4 Epoch: 14 Eval_loss: 0.006628468167036772\n",
      "Train:4 Epoch: 15 Eval_loss: 0.006039580795913935\n",
      "Train:4 Epoch: 16 Eval_loss: 0.0056440155021846294\n",
      "Train:4 Epoch: 17 Eval_loss: 0.00548517145216465\n",
      "Train:4 Epoch: 18 Eval_loss: 0.005334747489541769\n",
      "Train:4 Epoch: 19 Eval_loss: 0.005167028866708279\n",
      "Train:4 Epoch: 20 Eval_loss: 0.00508676003664732\n",
      "Train:4 Epoch: 21 Eval_loss: 0.004892962519079447\n",
      "Train:4 Epoch: 22 Eval_loss: 0.00467864703387022\n",
      "Train:4 Epoch: 23 Eval_loss: 0.004571059253066778\n",
      "Train:4 Epoch: 24 Eval_loss: 0.0044772992841899395\n",
      "Train:4 Epoch: 25 Eval_loss: 0.004445458762347698\n",
      "Train:4 Epoch: 26 Eval_loss: 0.004295246209949255\n",
      "Train:4 Epoch: 27 Eval_loss: 0.004144630860537291\n",
      "Train:4 Epoch: 28 Eval_loss: 0.004065586719661951\n",
      "Train:4 Epoch: 29 Eval_loss: 0.003971392288804054\n",
      "Train:4 Epoch: 30 Eval_loss: 0.0039873551577329636\n",
      "Train:4 Epoch: 31 Eval_loss: 0.0038694427348673344\n",
      "Train:4 Epoch: 32 Eval_loss: 0.003793490817770362\n",
      "Train:4 Epoch: 33 Eval_loss: 0.003922266885638237\n",
      "Train:4 Epoch: 34 Eval_loss: 0.003826119238510728\n",
      "Train:4 Epoch: 35 Eval_loss: 0.0038668212946504354\n",
      "Train:4 Epoch: 36 Eval_loss: 0.0037112142890691757\n",
      "Train:4 Epoch: 37 Eval_loss: 0.003697846783325076\n",
      "Train:4 Epoch: 38 Eval_loss: 0.003716881386935711\n",
      "Train:4 Epoch: 39 Eval_loss: 0.003596382914111018\n",
      "Train:4 Epoch: 40 Eval_loss: 0.0034621248487383127\n",
      "Train:4 Epoch: 41 Eval_loss: 0.0034522060304880142\n",
      "Train:4 Epoch: 42 Eval_loss: 0.0035005270037800074\n",
      "Train:4 Epoch: 43 Eval_loss: 0.003357770387083292\n",
      "Train:4 Epoch: 44 Eval_loss: 0.003386742202565074\n",
      "Train:4 Epoch: 45 Eval_loss: 0.003402948612347245\n",
      "Train:4 Epoch: 46 Eval_loss: 0.0032583964057266712\n",
      "Train:4 Epoch: 47 Eval_loss: 0.003271902445703745\n",
      "Train:4 Epoch: 48 Eval_loss: 0.0032602157443761826\n",
      "Train:4 Epoch: 49 Eval_loss: 0.0032449497375637293\n",
      "Train:4 Epoch: 50 Eval_loss: 0.0032551689073443413\n",
      "Train:4 Epoch: 51 Eval_loss: 0.0032062488608062267\n",
      "Train:4 Epoch: 52 Eval_loss: 0.003101046197116375\n",
      "Train:4 Epoch: 53 Eval_loss: 0.0030760173685848713\n",
      "Train:4 Epoch: 54 Eval_loss: 0.003021596698090434\n",
      "Train:4 Epoch: 55 Eval_loss: 0.003087416524067521\n",
      "Train:4 Epoch: 56 Eval_loss: 0.003130766563117504\n",
      "Train:4 Epoch: 57 Eval_loss: 0.003055053995922208\n",
      "Train:4 Epoch: 58 Eval_loss: 0.002960129175335169\n",
      "Train:4 Epoch: 59 Eval_loss: 0.0029864103998988867\n",
      "Train:4 Epoch: 60 Eval_loss: 0.0029725246131420135\n",
      "Train:4 Epoch: 61 Eval_loss: 0.002798348432406783\n",
      "Train:4 Epoch: 62 Eval_loss: 0.0028710062615573406\n",
      "Train:4 Epoch: 63 Eval_loss: 0.0029010006692260504\n",
      "Train:4 Epoch: 64 Eval_loss: 0.002849492710083723\n",
      "Train:4 Epoch: 65 Eval_loss: 0.0027427866589277983\n",
      "Train:4 Epoch: 66 Eval_loss: 0.0026935634668916464\n",
      "Train:4 Epoch: 67 Eval_loss: 0.0027437626849859953\n",
      "Train:4 Epoch: 68 Eval_loss: 0.0026376114692538977\n",
      "Train:4 Epoch: 69 Eval_loss: 0.002624235348775983\n",
      "Train:4 Epoch: 70 Eval_loss: 0.002659851685166359\n",
      "Train:4 Epoch: 71 Eval_loss: 0.0026139304973185062\n",
      "Train:4 Epoch: 72 Eval_loss: 0.002645712811499834\n",
      "Train:4 Epoch: 73 Eval_loss: 0.0026050249580293894\n",
      "Train:4 Epoch: 74 Eval_loss: 0.002496983390301466\n",
      "Train:4 Epoch: 75 Eval_loss: 0.0025491714477539062\n",
      "Train:4 Epoch: 76 Eval_loss: 0.0025383299216628075\n",
      "Train:4 Epoch: 77 Eval_loss: 0.00248882663436234\n",
      "Train:4 Epoch: 78 Eval_loss: 0.002487564692273736\n",
      "Train:4 Epoch: 79 Eval_loss: 0.002434638561680913\n",
      "Train:4 Epoch: 80 Eval_loss: 0.002459669718518853\n",
      "Train:4 Epoch: 81 Eval_loss: 0.002404869766905904\n",
      "Train:4 Epoch: 82 Eval_loss: 0.002334033139050007\n",
      "Train:4 Epoch: 83 Eval_loss: 0.0023058434017002583\n",
      "Train:4 Epoch: 84 Eval_loss: 0.002219602931290865\n",
      "Train:4 Epoch: 85 Eval_loss: 0.002279554959386587\n",
      "Train:4 Epoch: 86 Eval_loss: 0.0022613455075770617\n",
      "Train:4 Epoch: 87 Eval_loss: 0.0022278144024312496\n",
      "Train:4 Epoch: 88 Eval_loss: 0.002250178949907422\n",
      "Train:4 Epoch: 89 Eval_loss: 0.0021229395642876625\n",
      "Train:4 Epoch: 90 Eval_loss: 0.0020984034053981304\n",
      "Train:4 Epoch: 91 Eval_loss: 0.002149738371372223\n",
      "Train:4 Epoch: 92 Eval_loss: 0.0020857418421655893\n",
      "Train:4 Epoch: 93 Eval_loss: 0.002065330743789673\n",
      "Train:4 Epoch: 94 Eval_loss: 0.0020227425266057253\n",
      "Train:4 Epoch: 95 Eval_loss: 0.0019774576649069786\n",
      "Train:4 Epoch: 96 Eval_loss: 0.0019457233138382435\n",
      "Train:4 Epoch: 97 Eval_loss: 0.001999654108658433\n",
      "Train:4 Epoch: 98 Eval_loss: 0.0019603227265179157\n",
      "Train:4 Epoch: 99 Eval_loss: 0.0019170268205925822\n",
      "Train:4 Epoch: 100 Eval_loss: 0.001943642389960587\n",
      "Train:4 Epoch: 101 Eval_loss: 0.0019096387550234795\n",
      "Train:4 Epoch: 102 Eval_loss: 0.0019253764767199755\n",
      "Train:4 Epoch: 103 Eval_loss: 0.0019153510220348835\n",
      "Train:4 Epoch: 104 Eval_loss: 0.0018257267074659467\n",
      "Train:4 Epoch: 105 Eval_loss: 0.0018284476827830076\n",
      "Train:4 Epoch: 106 Eval_loss: 0.001841970020905137\n",
      "Train:4 Epoch: 107 Eval_loss: 0.001830256194807589\n",
      "Train:4 Epoch: 108 Eval_loss: 0.001821801532059908\n",
      "Train:4 Epoch: 109 Eval_loss: 0.0017869482981041074\n",
      "Train:4 Epoch: 110 Eval_loss: 0.0017353675793856382\n",
      "Train:4 Epoch: 111 Eval_loss: 0.0017195348627865314\n",
      "Train:4 Epoch: 112 Eval_loss: 0.0017183998133987188\n",
      "Train:4 Epoch: 113 Eval_loss: 0.0016434480203315616\n",
      "Train:4 Epoch: 114 Eval_loss: 0.0016730313654989004\n",
      "Train:4 Epoch: 115 Eval_loss: 0.0016811543609946966\n",
      "Train:4 Epoch: 116 Eval_loss: 0.0016199889359995723\n",
      "Train:4 Epoch: 117 Eval_loss: 0.0015796273946762085\n",
      "Train:4 Epoch: 118 Eval_loss: 0.0015960873570293188\n",
      "Train:4 Epoch: 119 Eval_loss: 0.0015876188408583403\n",
      "Train:4 Epoch: 120 Eval_loss: 0.0016392291290685534\n",
      "Train:4 Epoch: 121 Eval_loss: 0.0016028021927922964\n",
      "Train:4 Epoch: 122 Eval_loss: 0.001617502304725349\n",
      "Train:4 Epoch: 123 Eval_loss: 0.0015917931450530887\n",
      "Train:4 Epoch: 124 Eval_loss: 0.0015695118345320225\n",
      "Train:4 Epoch: 125 Eval_loss: 0.001563967321999371\n",
      "Train:4 Epoch: 126 Eval_loss: 0.0015225057723000646\n",
      "Train:4 Epoch: 127 Eval_loss: 0.0014746200758963823\n",
      "Train:4 Epoch: 128 Eval_loss: 0.0014741708291694522\n",
      "Train:4 Epoch: 129 Eval_loss: 0.0014212653040885925\n",
      "Train:4 Epoch: 130 Eval_loss: 0.001412372337654233\n",
      "Train:4 Epoch: 131 Eval_loss: 0.001400241395458579\n",
      "Train:4 Epoch: 132 Eval_loss: 0.001359904883429408\n",
      "Train:4 Epoch: 133 Eval_loss: 0.001363464747555554\n",
      "Train:4 Epoch: 134 Eval_loss: 0.0013770557707175612\n",
      "Train:4 Epoch: 135 Eval_loss: 0.001352899125777185\n",
      "Train:4 Epoch: 136 Eval_loss: 0.0013546935515478253\n",
      "Train:4 Epoch: 137 Eval_loss: 0.001311912084929645\n",
      "Train:4 Epoch: 138 Eval_loss: 0.0013376246206462383\n",
      "Train:4 Epoch: 139 Eval_loss: 0.0013149805599823594\n",
      "Train:4 Epoch: 140 Eval_loss: 0.0012826445745304227\n",
      "Train:4 Epoch: 141 Eval_loss: 0.0012627571122720838\n",
      "Train:4 Epoch: 142 Eval_loss: 0.0012866933830082417\n",
      "Train:4 Epoch: 143 Eval_loss: 0.0012821309501305223\n",
      "Train:4 Epoch: 144 Eval_loss: 0.001268904423341155\n",
      "Train:4 Epoch: 145 Eval_loss: 0.0013011859264224768\n",
      "Train:4 Epoch: 146 Eval_loss: 0.0013300467981025577\n",
      "Train:4 Epoch: 147 Eval_loss: 0.0013043691869825125\n",
      "Train:4 Epoch: 148 Eval_loss: 0.0012722512474283576\n",
      "Train:4 Epoch: 149 Eval_loss: 0.001241240999661386\n",
      "Train:4 Epoch: 150 Eval_loss: 0.0012152459239587188\n",
      "Train:4 Epoch: 151 Eval_loss: 0.0011936579830944538\n",
      "Train:4 Epoch: 152 Eval_loss: 0.0011431955499574542\n",
      "Train:4 Epoch: 153 Eval_loss: 0.0011728137033060193\n",
      "Train:4 Epoch: 154 Eval_loss: 0.0011709692189469934\n",
      "Train:4 Epoch: 155 Eval_loss: 0.0011487881420180202\n",
      "Train:4 Epoch: 156 Eval_loss: 0.0011593136005103588\n",
      "Train:4 Epoch: 157 Eval_loss: 0.0012049792567268014\n",
      "Train:4 Epoch: 158 Eval_loss: 0.0011231065727770329\n",
      "Train:4 Epoch: 159 Eval_loss: 0.0010722980368882418\n",
      "Train:4 Epoch: 160 Eval_loss: 0.001133867772296071\n",
      "Train:4 Epoch: 161 Eval_loss: 0.001040386501699686\n",
      "Train:4 Epoch: 162 Eval_loss: 0.001038242713548243\n",
      "Train:4 Epoch: 163 Eval_loss: 0.0010487468680366874\n",
      "Train:4 Epoch: 164 Eval_loss: 0.0010055621387436986\n",
      "Train:4 Epoch: 165 Eval_loss: 0.0010188163723796606\n",
      "Train:4 Epoch: 166 Eval_loss: 0.0009889091597869992\n",
      "Train:4 Epoch: 167 Eval_loss: 0.001004546182230115\n",
      "Train:4 Epoch: 168 Eval_loss: 0.0009694080799818039\n",
      "Train:4 Epoch: 169 Eval_loss: 0.000982088502496481\n",
      "Train:4 Epoch: 170 Eval_loss: 0.0009380939300172031\n",
      "Train:4 Epoch: 171 Eval_loss: 0.0009649545536376536\n",
      "Train:4 Epoch: 172 Eval_loss: 0.0009479910368099809\n",
      "Train:4 Epoch: 173 Eval_loss: 0.000939115765504539\n",
      "Train:4 Epoch: 174 Eval_loss: 0.0010412120027467608\n",
      "Train:4 Epoch: 175 Eval_loss: 0.0009143853676505387\n",
      "Train:4 Epoch: 176 Eval_loss: 0.0009553821291774511\n",
      "Train:4 Epoch: 177 Eval_loss: 0.0009653543238528073\n",
      "Train:4 Epoch: 178 Eval_loss: 0.0009612140129320323\n",
      "Train:4 Epoch: 179 Eval_loss: 0.0009425079333595932\n",
      "Train:4 Epoch: 180 Eval_loss: 0.0009133281419053674\n",
      "Train:4 Epoch: 181 Eval_loss: 0.000885278801433742\n",
      "Train:4 Epoch: 182 Eval_loss: 0.0008728018729016185\n",
      "Train:4 Epoch: 183 Eval_loss: 0.0008622372406534851\n",
      "Train:4 Epoch: 184 Eval_loss: 0.0008716090233065188\n",
      "Train:4 Epoch: 185 Eval_loss: 0.0008785034879110754\n",
      "Train:4 Epoch: 186 Eval_loss: 0.0008265128126367927\n",
      "Train:4 Epoch: 187 Eval_loss: 0.0008299304754473269\n",
      "Train:4 Epoch: 188 Eval_loss: 0.0008236899157054722\n",
      "Train:4 Epoch: 189 Eval_loss: 0.0008189935469999909\n",
      "Train:4 Epoch: 190 Eval_loss: 0.0008290709229186177\n",
      "Train:4 Epoch: 191 Eval_loss: 0.0008417186327278614\n",
      "Train:4 Epoch: 192 Eval_loss: 0.0008392068557441235\n",
      "Train:4 Epoch: 193 Eval_loss: 0.0007944125100038946\n",
      "Train:4 Epoch: 194 Eval_loss: 0.0008898170199245214\n",
      "Train:4 Epoch: 195 Eval_loss: 0.0008280731271952391\n",
      "Train:4 Epoch: 196 Eval_loss: 0.0009664628887549043\n",
      "Train:4 Epoch: 197 Eval_loss: 0.0008625129703432322\n",
      "Train:4 Epoch: 198 Eval_loss: 0.0008537361864000559\n",
      "Train:4 Epoch: 199 Eval_loss: 0.0007809789385646582\n",
      "Train:4 Epoch: 200 Eval_loss: 0.0007806631037965417\n",
      "Train:4 Epoch: 201 Eval_loss: 0.0007173088961280882\n",
      "Train:4 Epoch: 202 Eval_loss: 0.0007158153457567096\n",
      "Train:4 Epoch: 203 Eval_loss: 0.0007271557697094977\n",
      "Train:4 Epoch: 204 Eval_loss: 0.0006943957414478064\n",
      "Train:4 Epoch: 205 Eval_loss: 0.0006776750087738037\n",
      "Train:4 Epoch: 206 Eval_loss: 0.0006584792281500995\n",
      "Train:4 Epoch: 207 Eval_loss: 0.000666655832901597\n",
      "Train:4 Epoch: 208 Eval_loss: 0.0006575867882929742\n",
      "Train:4 Epoch: 209 Eval_loss: 0.0006597129977308214\n",
      "Train:4 Epoch: 210 Eval_loss: 0.0006787837482988834\n",
      "Train:4 Epoch: 211 Eval_loss: 0.0006730298628099263\n",
      "Train:4 Epoch: 212 Eval_loss: 0.0006494810804724693\n",
      "Train:4 Epoch: 213 Eval_loss: 0.0006443174788728356\n",
      "Train:4 Epoch: 214 Eval_loss: 0.0006466340273618698\n",
      "Train:4 Epoch: 215 Eval_loss: 0.0007194679928943515\n",
      "Train:4 Epoch: 216 Eval_loss: 0.000683956197462976\n",
      "Train:4 Epoch: 217 Eval_loss: 0.000655006617307663\n",
      "Train:4 Epoch: 218 Eval_loss: 0.0006615555612370372\n",
      "Train:4 Epoch: 219 Eval_loss: 0.0007424725336022675\n",
      "Train:4 Epoch: 220 Eval_loss: 0.0006783895078115165\n",
      "Train:4 Epoch: 221 Eval_loss: 0.0006815846427343786\n",
      "Train:4 Epoch: 222 Eval_loss: 0.0006782950949855149\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "loss_func = nn.MSELoss(reduction='none')\n",
    "seed_torch(seed = 20000223)\n",
    "\n",
    "def eval(eval_loader, eval_len, model):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(eval_loader):\n",
    "        batch = batch.to(device)\n",
    "        res = model(batch)\n",
    "\n",
    "        s_idx = i*10\n",
    "        seq_len = [i-1 for i in eval_len[s_idx:s_idx+10]]\n",
    "        loss = loss_func(\n",
    "            res[:, 1:, :],\n",
    "            batch[:, :-1, 1:51]\n",
    "        )\n",
    "        \n",
    "        loss = torch.mean(sequence_mask(loss, seq_len))\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "# 准备CATE\n",
    "def prepare_submission(dataset, model):\n",
    "    cate = []\n",
    "    for i in range(10):\n",
    "        seq = dataset[i]\n",
    "        early = torch.Tensor(seq[0]).unsqueeze(0).to(device)\n",
    "        interention = torch.Tensor([seq[1]]).to(device)\n",
    "        ref = torch.Tensor([seq[2]]).to(device)\n",
    "        target = seq[3]-1\n",
    "        state_1 = model(early)\n",
    "        state_1 = state_1[0,-1,:]\n",
    "\n",
    "        input_2 = torch.cat(\n",
    "            [interention, state_1, state_1[interention.long()-1]], dim=-1\n",
    "        )\n",
    "        input_2 = torch.cat([early, input_2.reshape(1, 1,-1)], dim=1)\n",
    "        state_2 = model(input_2)\n",
    "        state_2 = state_2[0,-1,:]\n",
    "        \n",
    "        input_3 = torch.cat(\n",
    "            [ref, state_1, state_1[ref.long()-1]], dim=-1\n",
    "        )\n",
    "        input_3 = torch.cat([early, input_3.reshape(1, 1,-1)], dim=1)\n",
    "        state_3 = model(input_3)\n",
    "        state_3 = state_3[0,-1,:]\n",
    "        cate.append((state_3[target] - state_2[target]).item())\n",
    "    return cate\n",
    "\n",
    "\n",
    "CATE=[]\n",
    "EPOCH = [500, 500, 500, 500, 500]\n",
    "patience = 10\n",
    "for ex in range(5):\n",
    "    model = MyRNN().to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # local_dev\n",
    "    datas = [local_0, local_1, local_2, local_3, local_4]\n",
    "\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "    \n",
    "    for n in range(5):\n",
    "        train_data += datas[n]\n",
    "    eval_data = datas[ex]\n",
    "\n",
    "    train_set, train_len = pad_data(train_data)\n",
    "    eval_set, eval_len = pad_data(eval_data)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_set, batch_size=10, shuffle=False)\n",
    "\n",
    "    min_loss=float('inf')\n",
    "    count=0\n",
    "\n",
    "    for ep in range(EPOCH[ex]):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            res = model(batch)\n",
    "            s_idx = i*10\n",
    "            seq_len = [i-1 for i in train_len[s_idx:s_idx+10]]\n",
    "            loss = loss_func(\n",
    "                res[:, 1:, :],\n",
    "                batch[:, :-1, 1:51]\n",
    "            )\n",
    "            loss = torch.mean(sequence_mask(loss, seq_len))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        model.eval()\n",
    "        eval_loss = eval(eval_loader, eval_len, model)\n",
    "\n",
    "        if eval_loss.item()<min_loss:\n",
    "            count=0\n",
    "            best_dict=model.state_dict()\n",
    "            min_loss=eval_loss.item()\n",
    "        else:\n",
    "            count+=1\n",
    "        if count>=patience:\n",
    "            model.load_state_dict(best_dict)\n",
    "            break\n",
    "\n",
    "        print(f'Train:{ex} Epoch: {ep} Eval_loss: {eval_loss.item()}')\n",
    "    model.eval()\n",
    "    CATE.append(prepare_submission(datas[ex], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10068426058359081, 0.09570050665563447, 0.11524562246133392, 0.13592586389473615, 0.14302208116317588]\n",
      "0.11811566695169425\n"
     ]
    }
   ],
   "source": [
    "# local evaluation\n",
    "res = [np.sqrt(np.mean((label[i] - CATE[i]) ** 2)) for i in range(5)]\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:0 Epoch: 0 Eval_loss: 0.053027380257844925\n",
      "Train:0 Epoch: 1 Eval_loss: 0.02729126811027527\n",
      "Train:0 Epoch: 2 Eval_loss: 0.02048083022236824\n",
      "Train:0 Epoch: 3 Eval_loss: 0.015378325246274471\n",
      "Train:0 Epoch: 4 Eval_loss: 0.01484769769012928\n",
      "Train:0 Epoch: 5 Eval_loss: 0.014867782592773438\n",
      "Train:0 Epoch: 6 Eval_loss: 0.012649589218199253\n",
      "Train:0 Epoch: 7 Eval_loss: 0.012052160687744617\n",
      "Train:0 Epoch: 8 Eval_loss: 0.011289033107459545\n",
      "Train:0 Epoch: 9 Eval_loss: 0.011446896940469742\n",
      "Train:0 Epoch: 10 Eval_loss: 0.010604330338537693\n",
      "Train:0 Epoch: 11 Eval_loss: 0.010643239133059978\n",
      "Train:0 Epoch: 12 Eval_loss: 0.00964053813368082\n",
      "Train:0 Epoch: 13 Eval_loss: 0.0096889678388834\n",
      "Train:0 Epoch: 14 Eval_loss: 0.009406886994838715\n",
      "Train:0 Epoch: 15 Eval_loss: 0.009196938946843147\n",
      "Train:0 Epoch: 16 Eval_loss: 0.008272496983408928\n",
      "Train:0 Epoch: 17 Eval_loss: 0.007810272742062807\n",
      "Train:0 Epoch: 18 Eval_loss: 0.007265477906912565\n",
      "Train:0 Epoch: 19 Eval_loss: 0.007224338594824076\n",
      "Train:0 Epoch: 20 Eval_loss: 0.007052504923194647\n",
      "Train:0 Epoch: 21 Eval_loss: 0.007143177092075348\n",
      "Train:0 Epoch: 22 Eval_loss: 0.006601718720048666\n",
      "Train:0 Epoch: 23 Eval_loss: 0.006498066708445549\n",
      "Train:0 Epoch: 24 Eval_loss: 0.006326646078377962\n",
      "Train:0 Epoch: 25 Eval_loss: 0.0064474912360310555\n",
      "Train:0 Epoch: 26 Eval_loss: 0.006167448591440916\n",
      "Train:0 Epoch: 27 Eval_loss: 0.006145147606730461\n",
      "Train:0 Epoch: 28 Eval_loss: 0.005913702305406332\n",
      "Train:0 Epoch: 29 Eval_loss: 0.005969774443656206\n",
      "Train:0 Epoch: 30 Eval_loss: 0.005735746119171381\n",
      "Train:0 Epoch: 31 Eval_loss: 0.0057106888853013515\n",
      "Train:0 Epoch: 32 Eval_loss: 0.005766044836491346\n",
      "Train:0 Epoch: 33 Eval_loss: 0.005563803017139435\n",
      "Train:0 Epoch: 34 Eval_loss: 0.005772280506789684\n",
      "Train:0 Epoch: 35 Eval_loss: 0.005521408747881651\n",
      "Train:0 Epoch: 36 Eval_loss: 0.0053442735224962234\n",
      "Train:0 Epoch: 37 Eval_loss: 0.005320011638104916\n",
      "Train:0 Epoch: 38 Eval_loss: 0.004994983319193125\n",
      "Train:0 Epoch: 39 Eval_loss: 0.004982809070497751\n",
      "Train:0 Epoch: 40 Eval_loss: 0.004936042241752148\n",
      "Train:0 Epoch: 41 Eval_loss: 0.004775757435709238\n",
      "Train:0 Epoch: 42 Eval_loss: 0.0047243149019777775\n",
      "Train:0 Epoch: 43 Eval_loss: 0.004283676855266094\n",
      "Train:0 Epoch: 44 Eval_loss: 0.004548004362732172\n",
      "Train:0 Epoch: 45 Eval_loss: 0.004239948466420174\n",
      "Train:0 Epoch: 46 Eval_loss: 0.003968326840549707\n",
      "Train:0 Epoch: 47 Eval_loss: 0.0038825555238872766\n",
      "Train:0 Epoch: 48 Eval_loss: 0.0036781756207346916\n",
      "Train:0 Epoch: 49 Eval_loss: 0.0036666705273091793\n",
      "Train:0 Epoch: 50 Eval_loss: 0.003435328835621476\n",
      "Train:0 Epoch: 51 Eval_loss: 0.003495472250506282\n",
      "Train:0 Epoch: 52 Eval_loss: 0.003286216640844941\n",
      "Train:0 Epoch: 53 Eval_loss: 0.0033750073052942753\n",
      "Train:0 Epoch: 54 Eval_loss: 0.0033221824560314417\n",
      "Train:0 Epoch: 55 Eval_loss: 0.003236667951568961\n",
      "Train:0 Epoch: 56 Eval_loss: 0.0033241650089621544\n",
      "Train:0 Epoch: 57 Eval_loss: 0.0033299284987151623\n",
      "Train:0 Epoch: 58 Eval_loss: 0.003259035525843501\n",
      "Train:0 Epoch: 59 Eval_loss: 0.003405520925298333\n",
      "Train:0 Epoch: 60 Eval_loss: 0.0031762595754116774\n",
      "Train:0 Epoch: 61 Eval_loss: 0.00345595576800406\n",
      "Train:0 Epoch: 62 Eval_loss: 0.0031999321654438972\n",
      "Train:0 Epoch: 63 Eval_loss: 0.0031123224180191755\n",
      "Train:0 Epoch: 64 Eval_loss: 0.0032115147914737463\n",
      "Train:0 Epoch: 65 Eval_loss: 0.0032431473955512047\n",
      "Train:0 Epoch: 66 Eval_loss: 0.003157543484121561\n",
      "Train:0 Epoch: 67 Eval_loss: 0.002991753164678812\n",
      "Train:0 Epoch: 68 Eval_loss: 0.0029296090360730886\n",
      "Train:0 Epoch: 69 Eval_loss: 0.002890044590458274\n",
      "Train:0 Epoch: 70 Eval_loss: 0.0028140025679022074\n",
      "Train:0 Epoch: 71 Eval_loss: 0.002742759883403778\n",
      "Train:0 Epoch: 72 Eval_loss: 0.00261895265430212\n",
      "Train:0 Epoch: 73 Eval_loss: 0.00257442076690495\n",
      "Train:0 Epoch: 74 Eval_loss: 0.002669329522177577\n",
      "Train:0 Epoch: 75 Eval_loss: 0.0026168834883719683\n",
      "Train:0 Epoch: 76 Eval_loss: 0.0025324434973299503\n",
      "Train:0 Epoch: 77 Eval_loss: 0.0025459318421781063\n",
      "Train:0 Epoch: 78 Eval_loss: 0.0024413226637989283\n",
      "Train:0 Epoch: 79 Eval_loss: 0.002426497172564268\n",
      "Train:0 Epoch: 80 Eval_loss: 0.002302393550053239\n",
      "Train:0 Epoch: 81 Eval_loss: 0.002278182888403535\n",
      "Train:0 Epoch: 82 Eval_loss: 0.002269670134410262\n",
      "Train:0 Epoch: 83 Eval_loss: 0.0022916323505342007\n",
      "Train:0 Epoch: 84 Eval_loss: 0.0023042578250169754\n",
      "Train:0 Epoch: 85 Eval_loss: 0.00234524579718709\n",
      "Train:0 Epoch: 86 Eval_loss: 0.0022652565967291594\n",
      "Train:0 Epoch: 87 Eval_loss: 0.002204138319939375\n",
      "Train:0 Epoch: 88 Eval_loss: 0.0021396102383732796\n",
      "Train:0 Epoch: 89 Eval_loss: 0.002101481892168522\n",
      "Train:0 Epoch: 90 Eval_loss: 0.002010948024690151\n",
      "Train:0 Epoch: 91 Eval_loss: 0.0020613069646060467\n",
      "Train:0 Epoch: 92 Eval_loss: 0.0020911807660013437\n",
      "Train:0 Epoch: 93 Eval_loss: 0.002082228194922209\n",
      "Train:0 Epoch: 94 Eval_loss: 0.0021155790891498327\n",
      "Train:0 Epoch: 95 Eval_loss: 0.002018456347286701\n",
      "Train:0 Epoch: 96 Eval_loss: 0.0019484912045300007\n",
      "Train:0 Epoch: 97 Eval_loss: 0.001966632902622223\n",
      "Train:0 Epoch: 98 Eval_loss: 0.0019203564152121544\n",
      "Train:0 Epoch: 99 Eval_loss: 0.001941226888448\n",
      "Train:0 Epoch: 100 Eval_loss: 0.001928555080667138\n",
      "Train:0 Epoch: 101 Eval_loss: 0.0018894599052146077\n",
      "Train:0 Epoch: 102 Eval_loss: 0.001957312226295471\n",
      "Train:0 Epoch: 103 Eval_loss: 0.001968591706827283\n",
      "Train:0 Epoch: 104 Eval_loss: 0.0018837236566469073\n",
      "Train:0 Epoch: 105 Eval_loss: 0.0018272609449923038\n",
      "Train:0 Epoch: 106 Eval_loss: 0.0018835377413779497\n",
      "Train:0 Epoch: 107 Eval_loss: 0.0018904198659583926\n",
      "Train:0 Epoch: 108 Eval_loss: 0.0018632225692272186\n",
      "Train:0 Epoch: 109 Eval_loss: 0.0018285202095285058\n",
      "Train:0 Epoch: 110 Eval_loss: 0.0017823147354647517\n",
      "Train:0 Epoch: 111 Eval_loss: 0.0018704391550272703\n",
      "Train:0 Epoch: 112 Eval_loss: 0.0018816771917045116\n",
      "Train:0 Epoch: 113 Eval_loss: 0.0018523621838539839\n",
      "Train:0 Epoch: 114 Eval_loss: 0.0018612832063809037\n",
      "Train:0 Epoch: 115 Eval_loss: 0.0017948845634236932\n",
      "Train:0 Epoch: 116 Eval_loss: 0.0018443581648170948\n",
      "Train:0 Epoch: 117 Eval_loss: 0.001768729300238192\n",
      "Train:0 Epoch: 118 Eval_loss: 0.0017820040229707956\n",
      "Train:0 Epoch: 119 Eval_loss: 0.0017024941043928266\n",
      "Train:0 Epoch: 120 Eval_loss: 0.001739619066938758\n",
      "Train:0 Epoch: 121 Eval_loss: 0.0016833199188113213\n",
      "Train:0 Epoch: 122 Eval_loss: 0.001609027967788279\n",
      "Train:0 Epoch: 123 Eval_loss: 0.0015750289894640446\n",
      "Train:0 Epoch: 124 Eval_loss: 0.0015555950812995434\n",
      "Train:0 Epoch: 125 Eval_loss: 0.0015414110384881496\n",
      "Train:0 Epoch: 126 Eval_loss: 0.0015752227045595646\n",
      "Train:0 Epoch: 127 Eval_loss: 0.0015854067169129848\n",
      "Train:0 Epoch: 128 Eval_loss: 0.0015461177099496126\n",
      "Train:0 Epoch: 129 Eval_loss: 0.001550986897200346\n",
      "Train:0 Epoch: 130 Eval_loss: 0.0015915206167846918\n",
      "Train:0 Epoch: 131 Eval_loss: 0.0015144683420658112\n",
      "Train:0 Epoch: 132 Eval_loss: 0.001460694125853479\n",
      "Train:0 Epoch: 133 Eval_loss: 0.0014171527000144124\n",
      "Train:0 Epoch: 134 Eval_loss: 0.0014954000944271684\n",
      "Train:0 Epoch: 135 Eval_loss: 0.001426037517376244\n",
      "Train:0 Epoch: 136 Eval_loss: 0.0013966404367238283\n",
      "Train:0 Epoch: 137 Eval_loss: 0.0014408297138288617\n",
      "Train:0 Epoch: 138 Eval_loss: 0.0013802674366161227\n",
      "Train:0 Epoch: 139 Eval_loss: 0.0013113002059981227\n",
      "Train:0 Epoch: 140 Eval_loss: 0.0013183311093598604\n",
      "Train:0 Epoch: 141 Eval_loss: 0.0012998529709875584\n",
      "Train:0 Epoch: 142 Eval_loss: 0.001339794835075736\n",
      "Train:0 Epoch: 143 Eval_loss: 0.001294323243200779\n",
      "Train:0 Epoch: 144 Eval_loss: 0.0012645416427403688\n",
      "Train:0 Epoch: 145 Eval_loss: 0.001220352598465979\n",
      "Train:0 Epoch: 146 Eval_loss: 0.0012753841001540422\n",
      "Train:0 Epoch: 147 Eval_loss: 0.001295194262638688\n",
      "Train:0 Epoch: 148 Eval_loss: 0.001229028799571097\n",
      "Train:0 Epoch: 149 Eval_loss: 0.0012197294272482395\n",
      "Train:0 Epoch: 150 Eval_loss: 0.0012626152019947767\n",
      "Train:0 Epoch: 151 Eval_loss: 0.0012348777381703258\n",
      "Train:0 Epoch: 152 Eval_loss: 0.0012557004811242223\n",
      "Train:0 Epoch: 153 Eval_loss: 0.0012269699946045876\n",
      "Train:0 Epoch: 154 Eval_loss: 0.0011908338638022542\n",
      "Train:0 Epoch: 155 Eval_loss: 0.0011622575111687183\n",
      "Train:0 Epoch: 156 Eval_loss: 0.0011209753574803472\n",
      "Train:0 Epoch: 157 Eval_loss: 0.001192825729958713\n",
      "Train:0 Epoch: 158 Eval_loss: 0.0012369902106001973\n",
      "Train:0 Epoch: 159 Eval_loss: 0.0011935719521716237\n",
      "Train:0 Epoch: 160 Eval_loss: 0.0011721416376531124\n",
      "Train:0 Epoch: 161 Eval_loss: 0.0012355592334643006\n",
      "Train:0 Epoch: 162 Eval_loss: 0.001218751072883606\n",
      "Train:0 Epoch: 163 Eval_loss: 0.0012087991926819086\n",
      "Train:0 Epoch: 164 Eval_loss: 0.0011903432896360755\n",
      "Train:0 Epoch: 165 Eval_loss: 0.0012479901779443026\n",
      "Train:1 Epoch: 0 Eval_loss: 0.08147633820772171\n",
      "Train:1 Epoch: 1 Eval_loss: 0.03509749844670296\n",
      "Train:1 Epoch: 2 Eval_loss: 0.026853684335947037\n",
      "Train:1 Epoch: 3 Eval_loss: 0.02064143307507038\n",
      "Train:1 Epoch: 4 Eval_loss: 0.017819877713918686\n",
      "Train:1 Epoch: 5 Eval_loss: 0.017246011644601822\n",
      "Train:1 Epoch: 6 Eval_loss: 0.01584218442440033\n",
      "Train:1 Epoch: 7 Eval_loss: 0.015068473294377327\n",
      "Train:1 Epoch: 8 Eval_loss: 0.014272710308432579\n",
      "Train:1 Epoch: 9 Eval_loss: 0.013832706958055496\n",
      "Train:1 Epoch: 10 Eval_loss: 0.013715561479330063\n",
      "Train:1 Epoch: 11 Eval_loss: 0.013258415274322033\n",
      "Train:1 Epoch: 12 Eval_loss: 0.012567570433020592\n",
      "Train:1 Epoch: 13 Eval_loss: 0.012272021733224392\n",
      "Train:1 Epoch: 14 Eval_loss: 0.012051107361912727\n",
      "Train:1 Epoch: 15 Eval_loss: 0.011429781094193459\n",
      "Train:1 Epoch: 16 Eval_loss: 0.010954955592751503\n",
      "Train:1 Epoch: 17 Eval_loss: 0.010598652064800262\n",
      "Train:1 Epoch: 18 Eval_loss: 0.010072990320622921\n",
      "Train:1 Epoch: 19 Eval_loss: 0.009955927729606628\n",
      "Train:1 Epoch: 20 Eval_loss: 0.009542113170027733\n",
      "Train:1 Epoch: 21 Eval_loss: 0.009370970539748669\n",
      "Train:1 Epoch: 22 Eval_loss: 0.008780520409345627\n",
      "Train:1 Epoch: 23 Eval_loss: 0.008617032319307327\n",
      "Train:1 Epoch: 24 Eval_loss: 0.008449622429907322\n",
      "Train:1 Epoch: 25 Eval_loss: 0.00837080180644989\n",
      "Train:1 Epoch: 26 Eval_loss: 0.00800144299864769\n",
      "Train:1 Epoch: 27 Eval_loss: 0.00793426763266325\n",
      "Train:1 Epoch: 28 Eval_loss: 0.007742989342659712\n",
      "Train:1 Epoch: 29 Eval_loss: 0.0074317422695457935\n",
      "Train:1 Epoch: 30 Eval_loss: 0.007396302651613951\n",
      "Train:1 Epoch: 31 Eval_loss: 0.007179667241871357\n",
      "Train:1 Epoch: 32 Eval_loss: 0.006921785417944193\n",
      "Train:1 Epoch: 33 Eval_loss: 0.006862981710582972\n",
      "Train:1 Epoch: 34 Eval_loss: 0.006651256233453751\n",
      "Train:1 Epoch: 35 Eval_loss: 0.006460839882493019\n",
      "Train:1 Epoch: 36 Eval_loss: 0.006248814053833485\n",
      "Train:1 Epoch: 37 Eval_loss: 0.006150938104838133\n",
      "Train:1 Epoch: 38 Eval_loss: 0.00629653874784708\n",
      "Train:1 Epoch: 39 Eval_loss: 0.006134058348834515\n",
      "Train:1 Epoch: 40 Eval_loss: 0.0060597737319767475\n",
      "Train:1 Epoch: 41 Eval_loss: 0.006103011313825846\n",
      "Train:1 Epoch: 42 Eval_loss: 0.006012551486492157\n",
      "Train:1 Epoch: 43 Eval_loss: 0.005831311922520399\n",
      "Train:1 Epoch: 44 Eval_loss: 0.005838525947183371\n",
      "Train:1 Epoch: 45 Eval_loss: 0.005676661618053913\n",
      "Train:1 Epoch: 46 Eval_loss: 0.005503685679286718\n",
      "Train:1 Epoch: 47 Eval_loss: 0.00543004646897316\n",
      "Train:1 Epoch: 48 Eval_loss: 0.005518301390111446\n",
      "Train:1 Epoch: 49 Eval_loss: 0.005306529346853495\n",
      "Train:1 Epoch: 50 Eval_loss: 0.005181002896279097\n",
      "Train:1 Epoch: 51 Eval_loss: 0.005243772640824318\n",
      "Train:1 Epoch: 52 Eval_loss: 0.005037958733737469\n",
      "Train:1 Epoch: 53 Eval_loss: 0.005051524378359318\n",
      "Train:1 Epoch: 54 Eval_loss: 0.004977675154805183\n",
      "Train:1 Epoch: 55 Eval_loss: 0.004730553366243839\n",
      "Train:1 Epoch: 56 Eval_loss: 0.004699537064880133\n",
      "Train:1 Epoch: 57 Eval_loss: 0.004759571515023708\n",
      "Train:1 Epoch: 58 Eval_loss: 0.004754340276122093\n",
      "Train:1 Epoch: 59 Eval_loss: 0.004734370857477188\n",
      "Train:1 Epoch: 60 Eval_loss: 0.0046225301921367645\n",
      "Train:1 Epoch: 61 Eval_loss: 0.004687380511313677\n",
      "Train:1 Epoch: 62 Eval_loss: 0.004597991239279509\n",
      "Train:1 Epoch: 63 Eval_loss: 0.004507830832153559\n",
      "Train:1 Epoch: 64 Eval_loss: 0.0044200243428349495\n",
      "Train:1 Epoch: 65 Eval_loss: 0.004441104829311371\n",
      "Train:1 Epoch: 66 Eval_loss: 0.004389199893921614\n",
      "Train:1 Epoch: 67 Eval_loss: 0.004420437850058079\n",
      "Train:1 Epoch: 68 Eval_loss: 0.0041958908550441265\n",
      "Train:1 Epoch: 69 Eval_loss: 0.004120230674743652\n",
      "Train:1 Epoch: 70 Eval_loss: 0.0041912877932190895\n",
      "Train:1 Epoch: 71 Eval_loss: 0.004118734039366245\n",
      "Train:1 Epoch: 72 Eval_loss: 0.004260975401848555\n",
      "Train:1 Epoch: 73 Eval_loss: 0.004192857537418604\n",
      "Train:1 Epoch: 74 Eval_loss: 0.004150288179516792\n",
      "Train:1 Epoch: 75 Eval_loss: 0.004176727030426264\n",
      "Train:1 Epoch: 76 Eval_loss: 0.004048975184559822\n",
      "Train:1 Epoch: 77 Eval_loss: 0.004054477903991938\n",
      "Train:1 Epoch: 78 Eval_loss: 0.0039365170523524284\n",
      "Train:1 Epoch: 79 Eval_loss: 0.003937457222491503\n",
      "Train:1 Epoch: 80 Eval_loss: 0.0038428911939263344\n",
      "Train:1 Epoch: 81 Eval_loss: 0.0038993083871901035\n",
      "Train:1 Epoch: 82 Eval_loss: 0.0038778334856033325\n",
      "Train:1 Epoch: 83 Eval_loss: 0.0038450132124125957\n",
      "Train:1 Epoch: 84 Eval_loss: 0.0037306102458387613\n",
      "Train:1 Epoch: 85 Eval_loss: 0.003681611269712448\n",
      "Train:1 Epoch: 86 Eval_loss: 0.0035560899414122105\n",
      "Train:1 Epoch: 87 Eval_loss: 0.0035488938447088003\n",
      "Train:1 Epoch: 88 Eval_loss: 0.0033707062248140574\n",
      "Train:1 Epoch: 89 Eval_loss: 0.003396758809685707\n",
      "Train:1 Epoch: 90 Eval_loss: 0.003180956467986107\n",
      "Train:1 Epoch: 91 Eval_loss: 0.0031939304899424314\n",
      "Train:1 Epoch: 92 Eval_loss: 0.0032039578072726727\n",
      "Train:1 Epoch: 93 Eval_loss: 0.003294240450486541\n",
      "Train:1 Epoch: 94 Eval_loss: 0.0030907108448445797\n",
      "Train:1 Epoch: 95 Eval_loss: 0.0031290019396692514\n",
      "Train:1 Epoch: 96 Eval_loss: 0.0032165965531021357\n",
      "Train:1 Epoch: 97 Eval_loss: 0.0032554948702454567\n",
      "Train:1 Epoch: 98 Eval_loss: 0.003149554366245866\n",
      "Train:1 Epoch: 99 Eval_loss: 0.003234943374991417\n",
      "Train:1 Epoch: 100 Eval_loss: 0.0031124348752200603\n",
      "Train:1 Epoch: 101 Eval_loss: 0.003152660094201565\n",
      "Train:1 Epoch: 102 Eval_loss: 0.0032638413831591606\n",
      "Train:1 Epoch: 103 Eval_loss: 0.0033025445882230997\n",
      "Train:2 Epoch: 0 Eval_loss: 0.10444861650466919\n",
      "Train:2 Epoch: 1 Eval_loss: 0.0495523065328598\n",
      "Train:2 Epoch: 2 Eval_loss: 0.036006007343530655\n",
      "Train:2 Epoch: 3 Eval_loss: 0.025412769988179207\n",
      "Train:2 Epoch: 4 Eval_loss: 0.022589512169361115\n",
      "Train:2 Epoch: 5 Eval_loss: 0.02210428938269615\n",
      "Train:2 Epoch: 6 Eval_loss: 0.019089818000793457\n",
      "Train:2 Epoch: 7 Eval_loss: 0.018579784780740738\n",
      "Train:2 Epoch: 8 Eval_loss: 0.017584361135959625\n",
      "Train:2 Epoch: 9 Eval_loss: 0.017735298722982407\n",
      "Train:2 Epoch: 10 Eval_loss: 0.017735252156853676\n",
      "Train:2 Epoch: 11 Eval_loss: 0.01670847274363041\n",
      "Train:2 Epoch: 12 Eval_loss: 0.015851084142923355\n",
      "Train:2 Epoch: 13 Eval_loss: 0.014870905317366123\n",
      "Train:2 Epoch: 14 Eval_loss: 0.014165272936224937\n",
      "Train:2 Epoch: 15 Eval_loss: 0.013750663958489895\n",
      "Train:2 Epoch: 16 Eval_loss: 0.013008260168135166\n",
      "Train:2 Epoch: 17 Eval_loss: 0.012061056680977345\n",
      "Train:2 Epoch: 18 Eval_loss: 0.011647957377135754\n",
      "Train:2 Epoch: 19 Eval_loss: 0.010702905245125294\n",
      "Train:2 Epoch: 20 Eval_loss: 0.010112427175045013\n",
      "Train:2 Epoch: 21 Eval_loss: 0.009813961572945118\n",
      "Train:2 Epoch: 22 Eval_loss: 0.009614375419914722\n",
      "Train:2 Epoch: 23 Eval_loss: 0.009318970143795013\n",
      "Train:2 Epoch: 24 Eval_loss: 0.008969900198280811\n",
      "Train:2 Epoch: 25 Eval_loss: 0.008736647665500641\n",
      "Train:2 Epoch: 26 Eval_loss: 0.008763902820646763\n",
      "Train:2 Epoch: 27 Eval_loss: 0.008616700768470764\n",
      "Train:2 Epoch: 28 Eval_loss: 0.008466740138828754\n",
      "Train:2 Epoch: 29 Eval_loss: 0.008571790531277657\n",
      "Train:2 Epoch: 30 Eval_loss: 0.008371371775865555\n",
      "Train:2 Epoch: 31 Eval_loss: 0.007980327121913433\n",
      "Train:2 Epoch: 32 Eval_loss: 0.00797603651881218\n",
      "Train:2 Epoch: 33 Eval_loss: 0.007886605337262154\n",
      "Train:2 Epoch: 34 Eval_loss: 0.0077269719913601875\n",
      "Train:2 Epoch: 35 Eval_loss: 0.007582442369312048\n",
      "Train:2 Epoch: 36 Eval_loss: 0.0075726741924881935\n",
      "Train:2 Epoch: 37 Eval_loss: 0.00734615046530962\n",
      "Train:2 Epoch: 38 Eval_loss: 0.007076694164425135\n",
      "Train:2 Epoch: 39 Eval_loss: 0.007039075717329979\n",
      "Train:2 Epoch: 40 Eval_loss: 0.00701236492022872\n",
      "Train:2 Epoch: 41 Eval_loss: 0.006776384077966213\n",
      "Train:2 Epoch: 42 Eval_loss: 0.0069294157437980175\n",
      "Train:2 Epoch: 43 Eval_loss: 0.006740047130733728\n",
      "Train:2 Epoch: 44 Eval_loss: 0.006503521464765072\n",
      "Train:2 Epoch: 45 Eval_loss: 0.006614042446017265\n",
      "Train:2 Epoch: 46 Eval_loss: 0.0065760742872953415\n",
      "Train:2 Epoch: 47 Eval_loss: 0.006547760684043169\n",
      "Train:2 Epoch: 48 Eval_loss: 0.006478932686150074\n",
      "Train:2 Epoch: 49 Eval_loss: 0.006591145880520344\n",
      "Train:2 Epoch: 50 Eval_loss: 0.006144219543784857\n",
      "Train:2 Epoch: 51 Eval_loss: 0.005915074143558741\n",
      "Train:2 Epoch: 52 Eval_loss: 0.0058150221593678\n",
      "Train:2 Epoch: 53 Eval_loss: 0.005893750116229057\n",
      "Train:2 Epoch: 54 Eval_loss: 0.005776470061391592\n",
      "Train:2 Epoch: 55 Eval_loss: 0.005600565578788519\n",
      "Train:2 Epoch: 56 Eval_loss: 0.005397208034992218\n",
      "Train:2 Epoch: 57 Eval_loss: 0.005306554958224297\n",
      "Train:2 Epoch: 58 Eval_loss: 0.005233576986938715\n",
      "Train:2 Epoch: 59 Eval_loss: 0.005247754044830799\n",
      "Train:2 Epoch: 60 Eval_loss: 0.005022320430725813\n",
      "Train:2 Epoch: 61 Eval_loss: 0.005047316197305918\n",
      "Train:2 Epoch: 62 Eval_loss: 0.004945738706737757\n",
      "Train:2 Epoch: 63 Eval_loss: 0.004743652418255806\n",
      "Train:2 Epoch: 64 Eval_loss: 0.004592400509864092\n",
      "Train:2 Epoch: 65 Eval_loss: 0.004575333558022976\n",
      "Train:2 Epoch: 66 Eval_loss: 0.00460794335231185\n",
      "Train:2 Epoch: 67 Eval_loss: 0.004559555556625128\n",
      "Train:2 Epoch: 68 Eval_loss: 0.004537784960120916\n",
      "Train:2 Epoch: 69 Eval_loss: 0.004498462192714214\n",
      "Train:2 Epoch: 70 Eval_loss: 0.004508941434323788\n",
      "Train:2 Epoch: 71 Eval_loss: 0.004556048661470413\n",
      "Train:2 Epoch: 72 Eval_loss: 0.0047537172213196754\n",
      "Train:2 Epoch: 73 Eval_loss: 0.004847584757953882\n",
      "Train:2 Epoch: 74 Eval_loss: 0.004890508018434048\n",
      "Train:2 Epoch: 75 Eval_loss: 0.004846505355089903\n",
      "Train:2 Epoch: 76 Eval_loss: 0.004545136820524931\n",
      "Train:2 Epoch: 77 Eval_loss: 0.0042249965481460094\n",
      "Train:2 Epoch: 78 Eval_loss: 0.004544355906546116\n",
      "Train:2 Epoch: 79 Eval_loss: 0.004098211880773306\n",
      "Train:2 Epoch: 80 Eval_loss: 0.004119871184229851\n",
      "Train:2 Epoch: 81 Eval_loss: 0.003952600993216038\n",
      "Train:2 Epoch: 82 Eval_loss: 0.00391380675137043\n",
      "Train:2 Epoch: 83 Eval_loss: 0.003850334556773305\n",
      "Train:2 Epoch: 84 Eval_loss: 0.003940656781196594\n",
      "Train:2 Epoch: 85 Eval_loss: 0.004008343908935785\n",
      "Train:2 Epoch: 86 Eval_loss: 0.003992005717009306\n",
      "Train:2 Epoch: 87 Eval_loss: 0.0038407645188272\n",
      "Train:2 Epoch: 88 Eval_loss: 0.0037797591648995876\n",
      "Train:2 Epoch: 89 Eval_loss: 0.0036577624268829823\n",
      "Train:2 Epoch: 90 Eval_loss: 0.003671440063044429\n",
      "Train:2 Epoch: 91 Eval_loss: 0.0035978821106255054\n",
      "Train:2 Epoch: 92 Eval_loss: 0.0035932939499616623\n",
      "Train:2 Epoch: 93 Eval_loss: 0.0036140347365289927\n",
      "Train:2 Epoch: 94 Eval_loss: 0.003525831736624241\n",
      "Train:2 Epoch: 95 Eval_loss: 0.0035303959157317877\n",
      "Train:2 Epoch: 96 Eval_loss: 0.003440817119553685\n",
      "Train:2 Epoch: 97 Eval_loss: 0.003420244436711073\n",
      "Train:2 Epoch: 98 Eval_loss: 0.0033725190442055464\n",
      "Train:2 Epoch: 99 Eval_loss: 0.003244758117944002\n",
      "Train:2 Epoch: 100 Eval_loss: 0.0032638730481266975\n",
      "Train:2 Epoch: 101 Eval_loss: 0.0032728174701333046\n",
      "Train:2 Epoch: 102 Eval_loss: 0.0032866871915757656\n",
      "Train:2 Epoch: 103 Eval_loss: 0.0033666444942355156\n",
      "Train:2 Epoch: 104 Eval_loss: 0.0032826124224811792\n",
      "Train:2 Epoch: 105 Eval_loss: 0.003241113154217601\n",
      "Train:2 Epoch: 106 Eval_loss: 0.00319127319380641\n",
      "Train:2 Epoch: 107 Eval_loss: 0.003168111201375723\n",
      "Train:2 Epoch: 108 Eval_loss: 0.0031713296193629503\n",
      "Train:2 Epoch: 109 Eval_loss: 0.0031201776582747698\n",
      "Train:2 Epoch: 110 Eval_loss: 0.0031405137851834297\n",
      "Train:2 Epoch: 111 Eval_loss: 0.003098685061559081\n",
      "Train:2 Epoch: 112 Eval_loss: 0.003063007490709424\n",
      "Train:2 Epoch: 113 Eval_loss: 0.0031512626446783543\n",
      "Train:2 Epoch: 114 Eval_loss: 0.0030257715843617916\n",
      "Train:2 Epoch: 115 Eval_loss: 0.0030332650057971478\n",
      "Train:2 Epoch: 116 Eval_loss: 0.0030157039873301983\n",
      "Train:2 Epoch: 117 Eval_loss: 0.0029988642781972885\n",
      "Train:2 Epoch: 118 Eval_loss: 0.002960388083010912\n",
      "Train:2 Epoch: 119 Eval_loss: 0.0028774901293218136\n",
      "Train:2 Epoch: 120 Eval_loss: 0.002843002788722515\n",
      "Train:2 Epoch: 121 Eval_loss: 0.0029207521583884954\n",
      "Train:2 Epoch: 122 Eval_loss: 0.002801634604111314\n",
      "Train:2 Epoch: 123 Eval_loss: 0.002737208968028426\n",
      "Train:2 Epoch: 124 Eval_loss: 0.002930811606347561\n",
      "Train:2 Epoch: 125 Eval_loss: 0.0030625988729298115\n",
      "Train:2 Epoch: 126 Eval_loss: 0.00298120710067451\n",
      "Train:2 Epoch: 127 Eval_loss: 0.003197462297976017\n",
      "Train:2 Epoch: 128 Eval_loss: 0.002858577063307166\n",
      "Train:2 Epoch: 129 Eval_loss: 0.0029180897399783134\n",
      "Train:2 Epoch: 130 Eval_loss: 0.002790245693176985\n",
      "Train:2 Epoch: 131 Eval_loss: 0.002713769907131791\n",
      "Train:2 Epoch: 132 Eval_loss: 0.0026789249386638403\n",
      "Train:2 Epoch: 133 Eval_loss: 0.002680004108697176\n",
      "Train:2 Epoch: 134 Eval_loss: 0.002869759453460574\n",
      "Train:2 Epoch: 135 Eval_loss: 0.002699490636587143\n",
      "Train:2 Epoch: 136 Eval_loss: 0.00257398490794003\n",
      "Train:2 Epoch: 137 Eval_loss: 0.0027471205685287714\n",
      "Train:2 Epoch: 138 Eval_loss: 0.0025822583120316267\n",
      "Train:2 Epoch: 139 Eval_loss: 0.0025323666632175446\n",
      "Train:2 Epoch: 140 Eval_loss: 0.0026859226636588573\n",
      "Train:2 Epoch: 141 Eval_loss: 0.0027599928434938192\n",
      "Train:2 Epoch: 142 Eval_loss: 0.002615883480757475\n",
      "Train:2 Epoch: 143 Eval_loss: 0.002654277253895998\n",
      "Train:2 Epoch: 144 Eval_loss: 0.0024628429673612118\n",
      "Train:2 Epoch: 145 Eval_loss: 0.002386726438999176\n",
      "Train:2 Epoch: 146 Eval_loss: 0.002369554480537772\n",
      "Train:2 Epoch: 147 Eval_loss: 0.0023449992295354605\n",
      "Train:2 Epoch: 148 Eval_loss: 0.002249970566481352\n",
      "Train:2 Epoch: 149 Eval_loss: 0.0021510347723960876\n",
      "Train:2 Epoch: 150 Eval_loss: 0.002157800365239382\n",
      "Train:2 Epoch: 151 Eval_loss: 0.0022325783502310514\n",
      "Train:2 Epoch: 152 Eval_loss: 0.0022479353938251734\n",
      "Train:2 Epoch: 153 Eval_loss: 0.0021792599000036716\n",
      "Train:2 Epoch: 154 Eval_loss: 0.0022043255157768726\n",
      "Train:2 Epoch: 155 Eval_loss: 0.00222354126162827\n",
      "Train:2 Epoch: 156 Eval_loss: 0.0024328897707164288\n",
      "Train:2 Epoch: 157 Eval_loss: 0.0023115992080420256\n",
      "Train:2 Epoch: 158 Eval_loss: 0.002317767357453704\n",
      "Train:3 Epoch: 0 Eval_loss: 0.05603422224521637\n",
      "Train:3 Epoch: 1 Eval_loss: 0.025826649740338326\n",
      "Train:3 Epoch: 2 Eval_loss: 0.016988418996334076\n",
      "Train:3 Epoch: 3 Eval_loss: 0.013697679154574871\n",
      "Train:3 Epoch: 4 Eval_loss: 0.012855815701186657\n",
      "Train:3 Epoch: 5 Eval_loss: 0.01224491372704506\n",
      "Train:3 Epoch: 6 Eval_loss: 0.010612370446324348\n",
      "Train:3 Epoch: 7 Eval_loss: 0.010000412352383137\n",
      "Train:3 Epoch: 8 Eval_loss: 0.009459291584789753\n",
      "Train:3 Epoch: 9 Eval_loss: 0.009211505763232708\n",
      "Train:3 Epoch: 10 Eval_loss: 0.008982155472040176\n",
      "Train:3 Epoch: 11 Eval_loss: 0.008757203817367554\n",
      "Train:3 Epoch: 12 Eval_loss: 0.008594198152422905\n",
      "Train:3 Epoch: 13 Eval_loss: 0.008405975997447968\n",
      "Train:3 Epoch: 14 Eval_loss: 0.008344072848558426\n",
      "Train:3 Epoch: 15 Eval_loss: 0.008018397726118565\n",
      "Train:3 Epoch: 16 Eval_loss: 0.007798335049301386\n",
      "Train:3 Epoch: 17 Eval_loss: 0.007297618314623833\n",
      "Train:3 Epoch: 18 Eval_loss: 0.006865492090582848\n",
      "Train:3 Epoch: 19 Eval_loss: 0.00674139428883791\n",
      "Train:3 Epoch: 20 Eval_loss: 0.006606374867260456\n",
      "Train:3 Epoch: 21 Eval_loss: 0.006416888441890478\n",
      "Train:3 Epoch: 22 Eval_loss: 0.005991564132273197\n",
      "Train:3 Epoch: 23 Eval_loss: 0.006061173044145107\n",
      "Train:3 Epoch: 24 Eval_loss: 0.005964961834251881\n",
      "Train:3 Epoch: 25 Eval_loss: 0.005820327438414097\n",
      "Train:3 Epoch: 26 Eval_loss: 0.005532890558242798\n",
      "Train:3 Epoch: 27 Eval_loss: 0.005631728563457727\n",
      "Train:3 Epoch: 28 Eval_loss: 0.0052916742861270905\n",
      "Train:3 Epoch: 29 Eval_loss: 0.005305968225002289\n",
      "Train:3 Epoch: 30 Eval_loss: 0.005036288406699896\n",
      "Train:3 Epoch: 31 Eval_loss: 0.004862787202000618\n",
      "Train:3 Epoch: 32 Eval_loss: 0.004936543293297291\n",
      "Train:3 Epoch: 33 Eval_loss: 0.004663445055484772\n",
      "Train:3 Epoch: 34 Eval_loss: 0.00457805534824729\n",
      "Train:3 Epoch: 35 Eval_loss: 0.0043753935024142265\n",
      "Train:3 Epoch: 36 Eval_loss: 0.004381777718663216\n",
      "Train:3 Epoch: 37 Eval_loss: 0.004282383248209953\n",
      "Train:3 Epoch: 38 Eval_loss: 0.004066992551088333\n",
      "Train:3 Epoch: 39 Eval_loss: 0.004100120160728693\n",
      "Train:3 Epoch: 40 Eval_loss: 0.0039656939916312695\n",
      "Train:3 Epoch: 41 Eval_loss: 0.003907386213541031\n",
      "Train:3 Epoch: 42 Eval_loss: 0.0038950806483626366\n",
      "Train:3 Epoch: 43 Eval_loss: 0.0038113314658403397\n",
      "Train:3 Epoch: 44 Eval_loss: 0.0037338698748499155\n",
      "Train:3 Epoch: 45 Eval_loss: 0.0035273630637675524\n",
      "Train:3 Epoch: 46 Eval_loss: 0.003536985954269767\n",
      "Train:3 Epoch: 47 Eval_loss: 0.0034453924745321274\n",
      "Train:3 Epoch: 48 Eval_loss: 0.003400087123736739\n",
      "Train:3 Epoch: 49 Eval_loss: 0.0034521138295531273\n",
      "Train:3 Epoch: 50 Eval_loss: 0.003262673271819949\n",
      "Train:3 Epoch: 51 Eval_loss: 0.003311160719022155\n",
      "Train:3 Epoch: 52 Eval_loss: 0.0031600622460246086\n",
      "Train:3 Epoch: 53 Eval_loss: 0.0031066746450960636\n",
      "Train:3 Epoch: 54 Eval_loss: 0.00310005946084857\n",
      "Train:3 Epoch: 55 Eval_loss: 0.002924098400399089\n",
      "Train:3 Epoch: 56 Eval_loss: 0.0028921510092914104\n",
      "Train:3 Epoch: 57 Eval_loss: 0.002855283208191395\n",
      "Train:3 Epoch: 58 Eval_loss: 0.002965107560157776\n",
      "Train:3 Epoch: 59 Eval_loss: 0.0027287923730909824\n",
      "Train:3 Epoch: 60 Eval_loss: 0.002699015662074089\n",
      "Train:3 Epoch: 61 Eval_loss: 0.0028101704083383083\n",
      "Train:3 Epoch: 62 Eval_loss: 0.002549552358686924\n",
      "Train:3 Epoch: 63 Eval_loss: 0.0025198315270245075\n",
      "Train:3 Epoch: 64 Eval_loss: 0.0026115921791642904\n",
      "Train:3 Epoch: 65 Eval_loss: 0.0025986379478126764\n",
      "Train:3 Epoch: 66 Eval_loss: 0.002499151276424527\n",
      "Train:3 Epoch: 67 Eval_loss: 0.0024645456578582525\n",
      "Train:3 Epoch: 68 Eval_loss: 0.002619067905470729\n",
      "Train:3 Epoch: 69 Eval_loss: 0.0023994818329811096\n",
      "Train:3 Epoch: 70 Eval_loss: 0.002419062191620469\n",
      "Train:3 Epoch: 71 Eval_loss: 0.0023756518494337797\n",
      "Train:3 Epoch: 72 Eval_loss: 0.0023384459782391787\n",
      "Train:3 Epoch: 73 Eval_loss: 0.002224933123216033\n",
      "Train:3 Epoch: 74 Eval_loss: 0.0022079020272940397\n",
      "Train:3 Epoch: 75 Eval_loss: 0.002155686030164361\n",
      "Train:3 Epoch: 76 Eval_loss: 0.0021586520597338676\n",
      "Train:3 Epoch: 77 Eval_loss: 0.0021285756956785917\n",
      "Train:3 Epoch: 78 Eval_loss: 0.0020887197460979223\n",
      "Train:3 Epoch: 79 Eval_loss: 0.0020824065431952477\n",
      "Train:3 Epoch: 80 Eval_loss: 0.0019573646131902933\n",
      "Train:3 Epoch: 81 Eval_loss: 0.0019428612431511283\n",
      "Train:3 Epoch: 82 Eval_loss: 0.001974158687517047\n",
      "Train:3 Epoch: 83 Eval_loss: 0.0019563145469874144\n",
      "Train:3 Epoch: 84 Eval_loss: 0.0019056915771216154\n",
      "Train:3 Epoch: 85 Eval_loss: 0.0018979811575263739\n",
      "Train:3 Epoch: 86 Eval_loss: 0.0018058051355183125\n",
      "Train:3 Epoch: 87 Eval_loss: 0.0018376236548647285\n",
      "Train:3 Epoch: 88 Eval_loss: 0.0018652903381735086\n",
      "Train:3 Epoch: 89 Eval_loss: 0.0017515089130029082\n",
      "Train:3 Epoch: 90 Eval_loss: 0.0017284806817770004\n",
      "Train:3 Epoch: 91 Eval_loss: 0.0017156157409772277\n",
      "Train:3 Epoch: 92 Eval_loss: 0.0016711835050955415\n",
      "Train:3 Epoch: 93 Eval_loss: 0.0016661997651681304\n",
      "Train:3 Epoch: 94 Eval_loss: 0.0016414470737800002\n",
      "Train:3 Epoch: 95 Eval_loss: 0.0016317545669153333\n",
      "Train:3 Epoch: 96 Eval_loss: 0.001617400674149394\n",
      "Train:3 Epoch: 97 Eval_loss: 0.0015913316747173667\n",
      "Train:3 Epoch: 98 Eval_loss: 0.0016178718069568276\n",
      "Train:3 Epoch: 99 Eval_loss: 0.0015264726243913174\n",
      "Train:3 Epoch: 100 Eval_loss: 0.0015504606999456882\n",
      "Train:3 Epoch: 101 Eval_loss: 0.0015595847507938743\n",
      "Train:3 Epoch: 102 Eval_loss: 0.001598437549546361\n",
      "Train:3 Epoch: 103 Eval_loss: 0.0015462671872228384\n",
      "Train:3 Epoch: 104 Eval_loss: 0.001608886057510972\n",
      "Train:3 Epoch: 105 Eval_loss: 0.0015529249794781208\n",
      "Train:3 Epoch: 106 Eval_loss: 0.0014711541589349508\n",
      "Train:3 Epoch: 107 Eval_loss: 0.0015010450733825564\n",
      "Train:3 Epoch: 108 Eval_loss: 0.001747541013173759\n",
      "Train:3 Epoch: 109 Eval_loss: 0.0015805343864485621\n",
      "Train:3 Epoch: 110 Eval_loss: 0.001519980258308351\n",
      "Train:3 Epoch: 111 Eval_loss: 0.0014868028229102492\n",
      "Train:3 Epoch: 112 Eval_loss: 0.0014515152433887124\n",
      "Train:3 Epoch: 113 Eval_loss: 0.0014778922777622938\n",
      "Train:3 Epoch: 114 Eval_loss: 0.0014095373917371035\n",
      "Train:3 Epoch: 115 Eval_loss: 0.001421300577931106\n",
      "Train:3 Epoch: 116 Eval_loss: 0.0014081569388508797\n",
      "Train:3 Epoch: 117 Eval_loss: 0.0013870388502255082\n",
      "Train:3 Epoch: 118 Eval_loss: 0.0014254796551540494\n",
      "Train:3 Epoch: 119 Eval_loss: 0.0014261347241699696\n",
      "Train:3 Epoch: 120 Eval_loss: 0.001397961750626564\n",
      "Train:3 Epoch: 121 Eval_loss: 0.0013235427904874086\n",
      "Train:3 Epoch: 122 Eval_loss: 0.0014062393456697464\n",
      "Train:3 Epoch: 123 Eval_loss: 0.0012996229343116283\n",
      "Train:3 Epoch: 124 Eval_loss: 0.0012889954959973693\n",
      "Train:3 Epoch: 125 Eval_loss: 0.0012553527485579252\n",
      "Train:3 Epoch: 126 Eval_loss: 0.0012802347773686051\n",
      "Train:3 Epoch: 127 Eval_loss: 0.0012074182741343975\n",
      "Train:3 Epoch: 128 Eval_loss: 0.001233650604262948\n",
      "Train:3 Epoch: 129 Eval_loss: 0.0011942549608647823\n",
      "Train:3 Epoch: 130 Eval_loss: 0.0011969254119321704\n",
      "Train:3 Epoch: 131 Eval_loss: 0.0012066427152603865\n",
      "Train:3 Epoch: 132 Eval_loss: 0.0012205978855490685\n",
      "Train:3 Epoch: 133 Eval_loss: 0.00114068656694144\n",
      "Train:3 Epoch: 134 Eval_loss: 0.0011916749645024538\n",
      "Train:3 Epoch: 135 Eval_loss: 0.001177819212898612\n",
      "Train:3 Epoch: 136 Eval_loss: 0.0011578543344512582\n",
      "Train:3 Epoch: 137 Eval_loss: 0.00121349620167166\n",
      "Train:3 Epoch: 138 Eval_loss: 0.0011365795508027077\n",
      "Train:3 Epoch: 139 Eval_loss: 0.0011301260674372315\n",
      "Train:3 Epoch: 140 Eval_loss: 0.001182176754809916\n",
      "Train:3 Epoch: 141 Eval_loss: 0.0011225691996514797\n",
      "Train:3 Epoch: 142 Eval_loss: 0.0011637192219495773\n",
      "Train:3 Epoch: 143 Eval_loss: 0.0010657123057171702\n",
      "Train:3 Epoch: 144 Eval_loss: 0.0011557448888197541\n",
      "Train:3 Epoch: 145 Eval_loss: 0.0010298894485458732\n",
      "Train:3 Epoch: 146 Eval_loss: 0.0010426818626001477\n",
      "Train:3 Epoch: 147 Eval_loss: 0.0011038121301680803\n",
      "Train:3 Epoch: 148 Eval_loss: 0.0010232593631371856\n",
      "Train:3 Epoch: 149 Eval_loss: 0.0010104648536071181\n",
      "Train:3 Epoch: 150 Eval_loss: 0.0010526649421080947\n",
      "Train:3 Epoch: 151 Eval_loss: 0.0010744843166321516\n",
      "Train:3 Epoch: 152 Eval_loss: 0.0010600796667858958\n",
      "Train:3 Epoch: 153 Eval_loss: 0.0010762885212898254\n",
      "Train:3 Epoch: 154 Eval_loss: 0.0010679721599444747\n",
      "Train:3 Epoch: 155 Eval_loss: 0.001119133667089045\n",
      "Train:3 Epoch: 156 Eval_loss: 0.0010095997713506222\n",
      "Train:3 Epoch: 157 Eval_loss: 0.000987931969575584\n",
      "Train:3 Epoch: 158 Eval_loss: 0.0009623458026908338\n",
      "Train:3 Epoch: 159 Eval_loss: 0.000978560303337872\n",
      "Train:3 Epoch: 160 Eval_loss: 0.0009566936059854925\n",
      "Train:3 Epoch: 161 Eval_loss: 0.0008998225093819201\n",
      "Train:3 Epoch: 162 Eval_loss: 0.0009320862009190023\n",
      "Train:3 Epoch: 163 Eval_loss: 0.0008733136346563697\n",
      "Train:3 Epoch: 164 Eval_loss: 0.0008927834569476545\n",
      "Train:3 Epoch: 165 Eval_loss: 0.0008946958696469665\n",
      "Train:3 Epoch: 166 Eval_loss: 0.0008602658053860068\n",
      "Train:3 Epoch: 167 Eval_loss: 0.0009124486241489649\n",
      "Train:3 Epoch: 168 Eval_loss: 0.0009017919655889273\n",
      "Train:3 Epoch: 169 Eval_loss: 0.0008810723084025085\n",
      "Train:3 Epoch: 170 Eval_loss: 0.0008399143116548657\n",
      "Train:3 Epoch: 171 Eval_loss: 0.0009304209379479289\n",
      "Train:3 Epoch: 172 Eval_loss: 0.000861904991324991\n",
      "Train:3 Epoch: 173 Eval_loss: 0.0009490829543210566\n",
      "Train:3 Epoch: 174 Eval_loss: 0.0008992142393253744\n",
      "Train:3 Epoch: 175 Eval_loss: 0.0009616702445782721\n",
      "Train:3 Epoch: 176 Eval_loss: 0.000983257545158267\n",
      "Train:3 Epoch: 177 Eval_loss: 0.0008204001351259649\n",
      "Train:3 Epoch: 178 Eval_loss: 0.0008637116989120841\n",
      "Train:3 Epoch: 179 Eval_loss: 0.000885956862475723\n",
      "Train:3 Epoch: 180 Eval_loss: 0.0008606585906818509\n",
      "Train:3 Epoch: 181 Eval_loss: 0.0009413021034561098\n",
      "Train:3 Epoch: 182 Eval_loss: 0.0008684906060807407\n",
      "Train:3 Epoch: 183 Eval_loss: 0.000846557377371937\n",
      "Train:3 Epoch: 184 Eval_loss: 0.0008106755558401346\n",
      "Train:3 Epoch: 185 Eval_loss: 0.0007858211174607277\n",
      "Train:3 Epoch: 186 Eval_loss: 0.0007329527870751917\n",
      "Train:3 Epoch: 187 Eval_loss: 0.0007634562207385898\n",
      "Train:3 Epoch: 188 Eval_loss: 0.0007167856674641371\n",
      "Train:3 Epoch: 189 Eval_loss: 0.0007484497036784887\n",
      "Train:3 Epoch: 190 Eval_loss: 0.0007208763854578137\n",
      "Train:3 Epoch: 191 Eval_loss: 0.0007290178327821195\n",
      "Train:3 Epoch: 192 Eval_loss: 0.000703865138348192\n",
      "Train:3 Epoch: 193 Eval_loss: 0.0007520234794355929\n",
      "Train:3 Epoch: 194 Eval_loss: 0.00074740219861269\n",
      "Train:3 Epoch: 195 Eval_loss: 0.0007890928536653519\n",
      "Train:3 Epoch: 196 Eval_loss: 0.0007555958582088351\n",
      "Train:3 Epoch: 197 Eval_loss: 0.0007610476459376514\n",
      "Train:3 Epoch: 198 Eval_loss: 0.0007118268986232579\n",
      "Train:3 Epoch: 199 Eval_loss: 0.0006975720170885324\n",
      "Train:3 Epoch: 200 Eval_loss: 0.0006985293584875762\n",
      "Train:3 Epoch: 201 Eval_loss: 0.000714444846380502\n",
      "Train:3 Epoch: 202 Eval_loss: 0.000682978832628578\n",
      "Train:3 Epoch: 203 Eval_loss: 0.0007491980795748532\n",
      "Train:3 Epoch: 204 Eval_loss: 0.0007505149696953595\n",
      "Train:3 Epoch: 205 Eval_loss: 0.0006791652995161712\n",
      "Train:3 Epoch: 206 Eval_loss: 0.0006631839205510914\n",
      "Train:3 Epoch: 207 Eval_loss: 0.0006399007397703826\n",
      "Train:3 Epoch: 208 Eval_loss: 0.0006328354356810451\n",
      "Train:3 Epoch: 209 Eval_loss: 0.0006339903338812292\n",
      "Train:3 Epoch: 210 Eval_loss: 0.0006329387542791665\n",
      "Train:3 Epoch: 211 Eval_loss: 0.0006594714941456914\n",
      "Train:3 Epoch: 212 Eval_loss: 0.0007086580735631287\n",
      "Train:3 Epoch: 213 Eval_loss: 0.0006599788903258741\n",
      "Train:3 Epoch: 214 Eval_loss: 0.0006211964646354318\n",
      "Train:3 Epoch: 215 Eval_loss: 0.0006100227474234998\n",
      "Train:3 Epoch: 216 Eval_loss: 0.0006392230861820281\n",
      "Train:3 Epoch: 217 Eval_loss: 0.0006106923101469874\n",
      "Train:3 Epoch: 218 Eval_loss: 0.0006133871502242982\n",
      "Train:3 Epoch: 219 Eval_loss: 0.0006164846126921475\n",
      "Train:3 Epoch: 220 Eval_loss: 0.0006187382386997342\n",
      "Train:3 Epoch: 221 Eval_loss: 0.0006003896123729646\n",
      "Train:3 Epoch: 222 Eval_loss: 0.0005887387087568641\n",
      "Train:3 Epoch: 223 Eval_loss: 0.0005942703573964536\n",
      "Train:3 Epoch: 224 Eval_loss: 0.0005881133256480098\n",
      "Train:3 Epoch: 225 Eval_loss: 0.000709696498233825\n",
      "Train:3 Epoch: 226 Eval_loss: 0.0006627971306443214\n",
      "Train:3 Epoch: 227 Eval_loss: 0.0006365716108120978\n",
      "Train:3 Epoch: 228 Eval_loss: 0.0006518480950035155\n",
      "Train:3 Epoch: 229 Eval_loss: 0.0005755071761086583\n",
      "Train:3 Epoch: 230 Eval_loss: 0.0005658296286128461\n",
      "Train:3 Epoch: 231 Eval_loss: 0.0006571125704795122\n",
      "Train:3 Epoch: 232 Eval_loss: 0.0005650710081681609\n",
      "Train:3 Epoch: 233 Eval_loss: 0.0006090588867664337\n",
      "Train:3 Epoch: 234 Eval_loss: 0.0005873231566511095\n",
      "Train:3 Epoch: 235 Eval_loss: 0.0005496339872479439\n",
      "Train:3 Epoch: 236 Eval_loss: 0.000508640892803669\n",
      "Train:3 Epoch: 237 Eval_loss: 0.0005105285090394318\n",
      "Train:3 Epoch: 238 Eval_loss: 0.0005083708092570305\n",
      "Train:3 Epoch: 239 Eval_loss: 0.0004897661856375635\n",
      "Train:3 Epoch: 240 Eval_loss: 0.0005188161158002913\n",
      "Train:3 Epoch: 241 Eval_loss: 0.0005476386286318302\n",
      "Train:3 Epoch: 242 Eval_loss: 0.0005468790768645704\n",
      "Train:3 Epoch: 243 Eval_loss: 0.0005420302040874958\n",
      "Train:3 Epoch: 244 Eval_loss: 0.0005170805379748344\n",
      "Train:3 Epoch: 245 Eval_loss: 0.0005378937930800021\n",
      "Train:3 Epoch: 246 Eval_loss: 0.0005011740140616894\n",
      "Train:3 Epoch: 247 Eval_loss: 0.0005350675201043487\n",
      "Train:3 Epoch: 248 Eval_loss: 0.0005300045013427734\n",
      "Train:4 Epoch: 0 Eval_loss: 0.03338339552283287\n",
      "Train:4 Epoch: 1 Eval_loss: 0.01573101431131363\n",
      "Train:4 Epoch: 2 Eval_loss: 0.012071402743458748\n",
      "Train:4 Epoch: 3 Eval_loss: 0.008081565611064434\n",
      "Train:4 Epoch: 4 Eval_loss: 0.006695753429085016\n",
      "Train:4 Epoch: 5 Eval_loss: 0.006329656112939119\n",
      "Train:4 Epoch: 6 Eval_loss: 0.005689959041774273\n",
      "Train:4 Epoch: 7 Eval_loss: 0.005235746968537569\n",
      "Train:4 Epoch: 8 Eval_loss: 0.005011991132050753\n",
      "Train:4 Epoch: 9 Eval_loss: 0.004634716082364321\n",
      "Train:4 Epoch: 10 Eval_loss: 0.004447671584784985\n",
      "Train:4 Epoch: 11 Eval_loss: 0.004444319289177656\n",
      "Train:4 Epoch: 12 Eval_loss: 0.004144120961427689\n",
      "Train:4 Epoch: 13 Eval_loss: 0.004024381283670664\n",
      "Train:4 Epoch: 14 Eval_loss: 0.0038651213981211185\n",
      "Train:4 Epoch: 15 Eval_loss: 0.0036348223220556974\n",
      "Train:4 Epoch: 16 Eval_loss: 0.003419000655412674\n",
      "Train:4 Epoch: 17 Eval_loss: 0.0030457305256277323\n",
      "Train:4 Epoch: 18 Eval_loss: 0.0029056421481072903\n",
      "Train:4 Epoch: 19 Eval_loss: 0.0028264622669667006\n",
      "Train:4 Epoch: 20 Eval_loss: 0.002718186704441905\n",
      "Train:4 Epoch: 21 Eval_loss: 0.002690436551347375\n",
      "Train:4 Epoch: 22 Eval_loss: 0.0025584264658391476\n",
      "Train:4 Epoch: 23 Eval_loss: 0.0025229251477867365\n",
      "Train:4 Epoch: 24 Eval_loss: 0.002429301617667079\n",
      "Train:4 Epoch: 25 Eval_loss: 0.002309870207682252\n",
      "Train:4 Epoch: 26 Eval_loss: 0.0023302333429455757\n",
      "Train:4 Epoch: 27 Eval_loss: 0.0022822353057563305\n",
      "Train:4 Epoch: 28 Eval_loss: 0.002166665391996503\n",
      "Train:4 Epoch: 29 Eval_loss: 0.0021788179874420166\n",
      "Train:4 Epoch: 30 Eval_loss: 0.002176465932279825\n",
      "Train:4 Epoch: 31 Eval_loss: 0.002157514449208975\n",
      "Train:4 Epoch: 32 Eval_loss: 0.0020671093370765448\n",
      "Train:4 Epoch: 33 Eval_loss: 0.002054210752248764\n",
      "Train:4 Epoch: 34 Eval_loss: 0.002062312327325344\n",
      "Train:4 Epoch: 35 Eval_loss: 0.0020320068579167128\n",
      "Train:4 Epoch: 36 Eval_loss: 0.0019968566484749317\n",
      "Train:4 Epoch: 37 Eval_loss: 0.001934907864779234\n",
      "Train:4 Epoch: 38 Eval_loss: 0.0018952388782054186\n",
      "Train:4 Epoch: 39 Eval_loss: 0.001818502671085298\n",
      "Train:4 Epoch: 40 Eval_loss: 0.001782480743713677\n",
      "Train:4 Epoch: 41 Eval_loss: 0.0017750633414834738\n",
      "Train:4 Epoch: 42 Eval_loss: 0.001747915637679398\n",
      "Train:4 Epoch: 43 Eval_loss: 0.0017338881734758615\n",
      "Train:4 Epoch: 44 Eval_loss: 0.0016805499326437712\n",
      "Train:4 Epoch: 45 Eval_loss: 0.0017309905961155891\n",
      "Train:4 Epoch: 46 Eval_loss: 0.0017853296594694257\n",
      "Train:4 Epoch: 47 Eval_loss: 0.001671988284215331\n",
      "Train:4 Epoch: 48 Eval_loss: 0.0016144479159265757\n",
      "Train:4 Epoch: 49 Eval_loss: 0.0016028758836910129\n",
      "Train:4 Epoch: 50 Eval_loss: 0.0016154362820088863\n",
      "Train:4 Epoch: 51 Eval_loss: 0.0015838253311812878\n",
      "Train:4 Epoch: 52 Eval_loss: 0.0015538448933511972\n",
      "Train:4 Epoch: 53 Eval_loss: 0.0015266332775354385\n",
      "Train:4 Epoch: 54 Eval_loss: 0.0014733488205820322\n",
      "Train:4 Epoch: 55 Eval_loss: 0.0014288522070273757\n",
      "Train:4 Epoch: 56 Eval_loss: 0.0014250788372009993\n",
      "Train:4 Epoch: 57 Eval_loss: 0.0014254916459321976\n",
      "Train:4 Epoch: 58 Eval_loss: 0.0014062714762985706\n",
      "Train:4 Epoch: 59 Eval_loss: 0.0013550026342272758\n",
      "Train:4 Epoch: 60 Eval_loss: 0.00141262321267277\n",
      "Train:4 Epoch: 61 Eval_loss: 0.0013669647742062807\n",
      "Train:4 Epoch: 62 Eval_loss: 0.0014188509667292237\n",
      "Train:4 Epoch: 63 Eval_loss: 0.0013487649848684669\n",
      "Train:4 Epoch: 64 Eval_loss: 0.001316844136454165\n",
      "Train:4 Epoch: 65 Eval_loss: 0.0012893113307654858\n",
      "Train:4 Epoch: 66 Eval_loss: 0.0012927358038723469\n",
      "Train:4 Epoch: 67 Eval_loss: 0.0012674826430156827\n",
      "Train:4 Epoch: 68 Eval_loss: 0.0012309497687965631\n",
      "Train:4 Epoch: 69 Eval_loss: 0.0012114980490878224\n",
      "Train:4 Epoch: 70 Eval_loss: 0.0011966467136517167\n",
      "Train:4 Epoch: 71 Eval_loss: 0.0011979618575423956\n",
      "Train:4 Epoch: 72 Eval_loss: 0.001185659784823656\n",
      "Train:4 Epoch: 73 Eval_loss: 0.0011918673990294337\n",
      "Train:4 Epoch: 74 Eval_loss: 0.0011594048701226711\n",
      "Train:4 Epoch: 75 Eval_loss: 0.0011734184809029102\n",
      "Train:4 Epoch: 76 Eval_loss: 0.001167272450402379\n",
      "Train:4 Epoch: 77 Eval_loss: 0.0011438598157837987\n",
      "Train:4 Epoch: 78 Eval_loss: 0.0011283423518761992\n",
      "Train:4 Epoch: 79 Eval_loss: 0.0011196722043678164\n",
      "Train:4 Epoch: 80 Eval_loss: 0.0011899678502231836\n",
      "Train:4 Epoch: 81 Eval_loss: 0.0011385987745597959\n",
      "Train:4 Epoch: 82 Eval_loss: 0.001111312652938068\n",
      "Train:4 Epoch: 83 Eval_loss: 0.0011121619027107954\n",
      "Train:4 Epoch: 84 Eval_loss: 0.001119127031415701\n",
      "Train:4 Epoch: 85 Eval_loss: 0.0010973373427987099\n",
      "Train:4 Epoch: 86 Eval_loss: 0.0011751222191378474\n",
      "Train:4 Epoch: 87 Eval_loss: 0.001178672187961638\n",
      "Train:4 Epoch: 88 Eval_loss: 0.0011007533175870776\n",
      "Train:4 Epoch: 89 Eval_loss: 0.001168760471045971\n",
      "Train:4 Epoch: 90 Eval_loss: 0.0010635053040459752\n",
      "Train:4 Epoch: 91 Eval_loss: 0.0011347379768267274\n",
      "Train:4 Epoch: 92 Eval_loss: 0.001104287221096456\n",
      "Train:4 Epoch: 93 Eval_loss: 0.00110691471491009\n",
      "Train:4 Epoch: 94 Eval_loss: 0.001026687677949667\n",
      "Train:4 Epoch: 95 Eval_loss: 0.0010447667445987463\n",
      "Train:4 Epoch: 96 Eval_loss: 0.0010648840107023716\n",
      "Train:4 Epoch: 97 Eval_loss: 0.0010462001664564013\n",
      "Train:4 Epoch: 98 Eval_loss: 0.0009983096970245242\n",
      "Train:4 Epoch: 99 Eval_loss: 0.0010456390446051955\n",
      "Train:4 Epoch: 100 Eval_loss: 0.0009662490920163691\n",
      "Train:4 Epoch: 101 Eval_loss: 0.0009733540937304497\n",
      "Train:4 Epoch: 102 Eval_loss: 0.0009401488350704312\n",
      "Train:4 Epoch: 103 Eval_loss: 0.0009359030518680811\n",
      "Train:4 Epoch: 104 Eval_loss: 0.0009081001044251025\n",
      "Train:4 Epoch: 105 Eval_loss: 0.0009278125362470746\n",
      "Train:4 Epoch: 106 Eval_loss: 0.0008659310988150537\n",
      "Train:4 Epoch: 107 Eval_loss: 0.0009203137014992535\n",
      "Train:4 Epoch: 108 Eval_loss: 0.0008877171203494072\n",
      "Train:4 Epoch: 109 Eval_loss: 0.0009401646675541997\n",
      "Train:4 Epoch: 110 Eval_loss: 0.0008737274911254644\n",
      "Train:4 Epoch: 111 Eval_loss: 0.0009034165996126831\n",
      "Train:4 Epoch: 112 Eval_loss: 0.0010412844130769372\n",
      "Train:4 Epoch: 113 Eval_loss: 0.0009920310694724321\n",
      "Train:4 Epoch: 114 Eval_loss: 0.0009093342814594507\n",
      "Train:4 Epoch: 115 Eval_loss: 0.0008571190410293639\n",
      "Train:4 Epoch: 116 Eval_loss: 0.000866565911564976\n",
      "Train:4 Epoch: 117 Eval_loss: 0.0008659344166517258\n",
      "Train:4 Epoch: 118 Eval_loss: 0.0008630548836663365\n",
      "Train:4 Epoch: 119 Eval_loss: 0.0008439865778200328\n",
      "Train:4 Epoch: 120 Eval_loss: 0.0008109716000035405\n",
      "Train:4 Epoch: 121 Eval_loss: 0.0007934339810162783\n",
      "Train:4 Epoch: 122 Eval_loss: 0.0008037911029532552\n",
      "Train:4 Epoch: 123 Eval_loss: 0.0007961869123391807\n",
      "Train:4 Epoch: 124 Eval_loss: 0.000775092572439462\n",
      "Train:4 Epoch: 125 Eval_loss: 0.0007752944948151708\n",
      "Train:4 Epoch: 126 Eval_loss: 0.0007398222805932164\n",
      "Train:4 Epoch: 127 Eval_loss: 0.0007604127749800682\n",
      "Train:4 Epoch: 128 Eval_loss: 0.0007341979653574526\n",
      "Train:4 Epoch: 129 Eval_loss: 0.000740967458114028\n",
      "Train:4 Epoch: 130 Eval_loss: 0.0007318102871067822\n",
      "Train:4 Epoch: 131 Eval_loss: 0.0007423214265145361\n",
      "Train:4 Epoch: 132 Eval_loss: 0.0007354258559644222\n",
      "Train:4 Epoch: 133 Eval_loss: 0.0007419426692649722\n",
      "Train:4 Epoch: 134 Eval_loss: 0.0007531612645834684\n",
      "Train:4 Epoch: 135 Eval_loss: 0.0007581533864140511\n",
      "Train:4 Epoch: 136 Eval_loss: 0.0007126450655050576\n",
      "Train:4 Epoch: 137 Eval_loss: 0.0007061949581839144\n",
      "Train:4 Epoch: 138 Eval_loss: 0.0006862334557808936\n",
      "Train:4 Epoch: 139 Eval_loss: 0.0006826347089372575\n",
      "Train:4 Epoch: 140 Eval_loss: 0.0006886160699650645\n",
      "Train:4 Epoch: 141 Eval_loss: 0.0006577903404831886\n",
      "Train:4 Epoch: 142 Eval_loss: 0.0006493778782896698\n",
      "Train:4 Epoch: 143 Eval_loss: 0.0006580594344995916\n",
      "Train:4 Epoch: 144 Eval_loss: 0.000646576751023531\n",
      "Train:4 Epoch: 145 Eval_loss: 0.0006476694252341986\n",
      "Train:4 Epoch: 146 Eval_loss: 0.0006453808164224029\n",
      "Train:4 Epoch: 147 Eval_loss: 0.0006505193887278438\n",
      "Train:4 Epoch: 148 Eval_loss: 0.000651318347081542\n",
      "Train:4 Epoch: 149 Eval_loss: 0.0006661416264250875\n",
      "Train:4 Epoch: 150 Eval_loss: 0.0006608966505154967\n",
      "Train:4 Epoch: 151 Eval_loss: 0.0007423368515446782\n",
      "Train:4 Epoch: 152 Eval_loss: 0.0006359792314469814\n",
      "Train:4 Epoch: 153 Eval_loss: 0.0006545778014697134\n",
      "Train:4 Epoch: 154 Eval_loss: 0.0006835443782620132\n",
      "Train:4 Epoch: 155 Eval_loss: 0.000645203108433634\n",
      "Train:4 Epoch: 156 Eval_loss: 0.0006425254396162927\n",
      "Train:4 Epoch: 157 Eval_loss: 0.0006186296232044697\n",
      "Train:4 Epoch: 158 Eval_loss: 0.0006229124846868217\n",
      "Train:4 Epoch: 159 Eval_loss: 0.0006480526644736528\n",
      "Train:4 Epoch: 160 Eval_loss: 0.000689726322889328\n",
      "Train:4 Epoch: 161 Eval_loss: 0.0006977090379223228\n",
      "Train:4 Epoch: 162 Eval_loss: 0.0006560604670085013\n",
      "Train:4 Epoch: 163 Eval_loss: 0.0006468561477959156\n",
      "Train:4 Epoch: 164 Eval_loss: 0.0006295975181274116\n",
      "Train:4 Epoch: 165 Eval_loss: 0.0006163790239952505\n",
      "Train:4 Epoch: 166 Eval_loss: 0.0006075576529838145\n",
      "Train:4 Epoch: 167 Eval_loss: 0.0006059952429495752\n",
      "Train:4 Epoch: 168 Eval_loss: 0.0006231996230781078\n",
      "Train:4 Epoch: 169 Eval_loss: 0.0006024964968673885\n",
      "Train:4 Epoch: 170 Eval_loss: 0.0005945053999312222\n",
      "Train:4 Epoch: 171 Eval_loss: 0.0005693076527677476\n",
      "Train:4 Epoch: 172 Eval_loss: 0.0005556443938985467\n",
      "Train:4 Epoch: 173 Eval_loss: 0.0005616611451841891\n",
      "Train:4 Epoch: 174 Eval_loss: 0.000551088189240545\n",
      "Train:4 Epoch: 175 Eval_loss: 0.0005617671413347125\n",
      "Train:4 Epoch: 176 Eval_loss: 0.0005426827119663358\n",
      "Train:4 Epoch: 177 Eval_loss: 0.0005616744165308774\n",
      "Train:4 Epoch: 178 Eval_loss: 0.000528396456502378\n",
      "Train:4 Epoch: 179 Eval_loss: 0.0005560106365010142\n",
      "Train:4 Epoch: 180 Eval_loss: 0.0005671783001162112\n",
      "Train:4 Epoch: 181 Eval_loss: 0.000597248668782413\n",
      "Train:4 Epoch: 182 Eval_loss: 0.0005816732300445437\n",
      "Train:4 Epoch: 183 Eval_loss: 0.0005507260793820024\n",
      "Train:4 Epoch: 184 Eval_loss: 0.0005130613571964204\n",
      "Train:4 Epoch: 185 Eval_loss: 0.0005239326856099069\n",
      "Train:4 Epoch: 186 Eval_loss: 0.0005247399676591158\n",
      "Train:4 Epoch: 187 Eval_loss: 0.0005206358036957681\n",
      "Train:4 Epoch: 188 Eval_loss: 0.000541473098564893\n",
      "Train:4 Epoch: 189 Eval_loss: 0.0005871992907486856\n",
      "Train:4 Epoch: 190 Eval_loss: 0.0005385828553698957\n",
      "Train:4 Epoch: 191 Eval_loss: 0.000580181775148958\n",
      "Train:4 Epoch: 192 Eval_loss: 0.0005939331604167819\n",
      "Train:4 Epoch: 193 Eval_loss: 0.0006071674870327115\n"
     ]
    }
   ],
   "source": [
    "# public\n",
    "seed_torch(seed = 20000223)\n",
    "CATE=[]\n",
    "EPOCH = [500, 500, 500, 500, 500]\n",
    "patience = 10\n",
    "for ex in range(5):\n",
    "    model = MyRNN().to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    datas = [processed_0, processed_1, processed_2, processed_3, processed_4]\n",
    "\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "    \n",
    "    for n in range(5):\n",
    "        train_data += datas[n]\n",
    "    eval_data = datas[ex]\n",
    "\n",
    "    train_set, train_len = pad_data(train_data)\n",
    "    eval_set, eval_len = pad_data(eval_data)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_set, batch_size=10, shuffle=False)\n",
    "\n",
    "    min_loss=float('inf')\n",
    "    count=0\n",
    "\n",
    "    for ep in range(EPOCH[ex]):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            res = model(batch)\n",
    "            s_idx = i*10\n",
    "            seq_len = [i-1 for i in train_len[s_idx:s_idx+10]]\n",
    "            loss = loss_func(\n",
    "                res[:, 1:, :],\n",
    "                batch[:, :-1, 1:51]\n",
    "            )\n",
    "            loss = torch.mean(sequence_mask(loss, seq_len))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        model.eval()\n",
    "        eval_loss = eval(eval_loader, eval_len, model)\n",
    "\n",
    "        if eval_loss.item()<min_loss:\n",
    "            count=0\n",
    "            best_dict=model.state_dict()\n",
    "            min_loss=eval_loss.item()\n",
    "        else:\n",
    "            count+=1\n",
    "        if count>=patience:\n",
    "            model.load_state_dict(best_dict)\n",
    "            break\n",
    "\n",
    "        print(f'Train:{ex} Epoch: {ep} Eval_loss: {eval_loss.item()}')\n",
    "    model.eval()\n",
    "    CATE.append(prepare_submission(datas[ex], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result to cate_estimate.npy\n",
    "np.save(\"cate_estimate.npy\", CATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:0 Epoch: 0 Eval_loss: 0.081059031188488\n",
      "Train:0 Epoch: 1 Eval_loss: 0.04812378063797951\n",
      "Train:0 Epoch: 2 Eval_loss: 0.041067443788051605\n",
      "Train:0 Epoch: 3 Eval_loss: 0.03248113766312599\n",
      "Train:0 Epoch: 4 Eval_loss: 0.03103226236999035\n",
      "Train:0 Epoch: 5 Eval_loss: 0.030827386304736137\n",
      "Train:0 Epoch: 6 Eval_loss: 0.030596664175391197\n",
      "Train:0 Epoch: 7 Eval_loss: 0.02817377820611\n",
      "Train:0 Epoch: 8 Eval_loss: 0.027250951156020164\n",
      "Train:0 Epoch: 9 Eval_loss: 0.027620771899819374\n",
      "Train:0 Epoch: 10 Eval_loss: 0.023152358829975128\n",
      "Train:0 Epoch: 11 Eval_loss: 0.020443998277187347\n",
      "Train:0 Epoch: 12 Eval_loss: 0.016354717314243317\n",
      "Train:0 Epoch: 13 Eval_loss: 0.014650973491370678\n",
      "Train:0 Epoch: 14 Eval_loss: 0.013722137548029423\n",
      "Train:0 Epoch: 15 Eval_loss: 0.01306401938199997\n",
      "Train:0 Epoch: 16 Eval_loss: 0.012532321736216545\n",
      "Train:0 Epoch: 17 Eval_loss: 0.011816257610917091\n",
      "Train:0 Epoch: 18 Eval_loss: 0.010917384177446365\n",
      "Train:0 Epoch: 19 Eval_loss: 0.010485250502824783\n",
      "Train:0 Epoch: 20 Eval_loss: 0.010347082279622555\n",
      "Train:0 Epoch: 21 Eval_loss: 0.010209296829998493\n",
      "Train:0 Epoch: 22 Eval_loss: 0.010330164805054665\n",
      "Train:0 Epoch: 23 Eval_loss: 0.009764212183654308\n",
      "Train:0 Epoch: 24 Eval_loss: 0.009468533098697662\n",
      "Train:0 Epoch: 25 Eval_loss: 0.009537209756672382\n",
      "Train:0 Epoch: 26 Eval_loss: 0.008990379050374031\n",
      "Train:0 Epoch: 27 Eval_loss: 0.008846087381243706\n",
      "Train:0 Epoch: 28 Eval_loss: 0.008453115820884705\n",
      "Train:0 Epoch: 29 Eval_loss: 0.008027217350900173\n",
      "Train:0 Epoch: 30 Eval_loss: 0.007904011756181717\n",
      "Train:0 Epoch: 31 Eval_loss: 0.007359892129898071\n",
      "Train:0 Epoch: 32 Eval_loss: 0.007327498402446508\n",
      "Train:0 Epoch: 33 Eval_loss: 0.007195943966507912\n",
      "Train:0 Epoch: 34 Eval_loss: 0.00693945586681366\n",
      "Train:0 Epoch: 35 Eval_loss: 0.006769211497157812\n",
      "Train:0 Epoch: 36 Eval_loss: 0.006483656354248524\n",
      "Train:0 Epoch: 37 Eval_loss: 0.006644072011113167\n",
      "Train:0 Epoch: 38 Eval_loss: 0.006301264278590679\n",
      "Train:0 Epoch: 39 Eval_loss: 0.006239784881472588\n",
      "Train:0 Epoch: 40 Eval_loss: 0.006267801858484745\n",
      "Train:0 Epoch: 41 Eval_loss: 0.005989834666252136\n"
     ]
    }
   ],
   "source": [
    "# private\n",
    "seed_torch(seed = 20000223)\n",
    "CATE=[]\n",
    "EPOCH = [500, 500, 500, 500, 500]\n",
    "patience = 10\n",
    "for ex in range(5):\n",
    "    model = MyRNN().to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    datas = [private_0, private_1, private_2, private_3, private_4]\n",
    "\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "    \n",
    "    for n in range(5):\n",
    "        train_data += datas[n]\n",
    "    eval_data = datas[ex]\n",
    "\n",
    "    train_set, train_len = pad_data(train_data)\n",
    "    eval_set, eval_len = pad_data(eval_data)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_set, batch_size=10, shuffle=False)\n",
    "\n",
    "    min_loss=float('inf')\n",
    "    count=0\n",
    "\n",
    "    for ep in range(EPOCH[ex]):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            res = model(batch)\n",
    "            s_idx = i*10\n",
    "            seq_len = [i-1 for i in train_len[s_idx:s_idx+10]]\n",
    "            loss = loss_func(\n",
    "                res[:, 1:, :],\n",
    "                batch[:, :-1, 1:51]\n",
    "            )\n",
    "            loss = torch.mean(sequence_mask(loss, seq_len))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        model.eval()\n",
    "        eval_loss = eval(eval_loader, eval_len, model)\n",
    "\n",
    "        if eval_loss.item()<min_loss:\n",
    "            count=0\n",
    "            best_dict=model.state_dict()\n",
    "            min_loss=eval_loss.item()\n",
    "        else:\n",
    "            count+=1\n",
    "        if count>=patience:\n",
    "            model.load_state_dict(best_dict)\n",
    "            break\n",
    "\n",
    "        print(f'Train:{ex} Epoch: {ep} Eval_loss: {eval_loss.item()}')\n",
    "    model.eval()\n",
    "    CATE.append(prepare_submission(datas[ex], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result to cate_estimate.npy\n",
    "np.save(\"cate_estimate.npy\", CATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "After running code, the result would save in cate_estimate.npy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4f5488a88fb31434cb118f0a480ee6ad53cd8ab91e0f4a23af51d43708b99b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
